{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4ï¸âƒ£ Purpose of a Validation Set in Machine Learning ğŸ¤–ğŸ“Š**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ’¡ Real-Life Analogy: Training for a Football Match âš½**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are **training a football team** for an upcoming match:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ï¸âƒ£ **Training Set (Practice Drills):** Players learn new skills & tactics in training.  \n",
    "2ï¸âƒ£ **Validation Set (Practice Match):** You test tactics **before the actual game** to see what works.  \n",
    "3ï¸âƒ£ **Test Set (Real Match):** The real competitionâ€”**final performance evaluation**!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“Œ **In Machine Learning, the validation set helps fine-tune a model before final testing!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ“Œ What is a Validation Set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **A validation set is a portion of the dataset used to tune the model's hyperparameters and evaluate its performance during training.**  \n",
    "âœ… It helps determine **when to stop training** and **avoid overfitting**.  \n",
    "âœ… The model is trained on the **training set** and tested on the **validation set** to improve performance **before** final testing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“Œ **Key Idea:**  \n",
    "- **Training Set:** Used to **train** the model.  \n",
    "- **Validation Set:** Used to **fine-tune** and adjust hyperparameters.  \n",
    "- **Test Set:** Used for **final evaluation** (never seen before).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **Mathematical Notation:**  \n",
    "If $ D $ is the full dataset, we split it as:  \n",
    "$$\n",
    "D = D_{\\text{train}} \\cup D_{\\text{val}} \\cup D_{\\text{test}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ“Š Example: Using a Validation Set in Football (Predicting Player Performance) âš½**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to predict whether a player will **score in a match** based on:  \n",
    "- **Shots on target ğŸ¯**  \n",
    "- **Minutes played â³**  \n",
    "- **Opposition strength ğŸ†**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“Œ **Dataset Split:**  \n",
    "| Data | Example | Usage |  \n",
    "|------|---------|------|  \n",
    "| **Training Set** | Matches from **2018-2021** | Used to train the model. |  \n",
    "| **Validation Set** | Matches from **2022** | Used to fine-tune parameters. |  \n",
    "| **Test Set** | Matches from **2023** | Used for final evaluation. |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **Why Use a Validation Set?**  \n",
    "- Without it, the model might **overfit** and perform poorly on 2023 games.  \n",
    "- The validation set ensures the model **generalizes well before testing**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ“Š Example: Using a Validation Set in NBA Analytics ğŸ€**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to predict if an NBA team will **win or lose** based on:  \n",
    "- **3-point percentage ğŸ¯**  \n",
    "- **Turnovers per game ğŸ”„**  \n",
    "- **Defensive efficiency ğŸ€**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“Œ **Dataset Split:**  \n",
    "| Data | Example | Usage |  \n",
    "|------|---------|------|  \n",
    "| **Training Set** | Games from **2010-2018** | Train model on historical trends. |  \n",
    "| **Validation Set** | Games from **2019-2021** | Fine-tune hyperparameters. |  \n",
    "| **Test Set** | Games from **2022** | Evaluate final model accuracy. |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **Why?**  \n",
    "- If the model **performs well on validation data**, it will likely **generalize** to test data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ†š Validation Set vs. Test Set: Key Differences**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Validation Set âœ… | Test Set âœ… |  \n",
    "|---------|-----------------|--------------|  \n",
    "| **Purpose** | Used for tuning hyperparameters & avoiding overfitting. | Final evaluation of model performance. |  \n",
    "| **When Used?** | During training. | After model training is complete. |  \n",
    "| **Exposure to Model?** | Model **sees** this data during tuning. | Model **never sees** this data until final testing. |  \n",
    "| **Adjustments?** | Hyperparameters are adjusted based on validation performance. | No changes are made after test evaluation. |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ”„ Types of Validation Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **1ï¸âƒ£ Simple Train-Validation-Test Split (80-10-10 or 70-15-15)**  \n",
    "- **Best for large datasets.**  \n",
    "- Example:  \n",
    "  - **70% Training**  \n",
    "  - **15% Validation**  \n",
    "  - **15% Testing**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **2ï¸âƒ£ K-Fold Cross-Validation (Good for Small Data)**  \n",
    "- Splits data into **K parts** and rotates the validation set.  \n",
    "- Example: **5-Fold CV** â†’ Each part is used as a validation set once.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **3ï¸âƒ£ Leave-One-Out Cross-Validation (LOOCV)**  \n",
    "- Each sample is tested separately (best for small datasets).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **4ï¸âƒ£ Time-Based Validation Split (Used in Finance & Sports)**  \n",
    "- Example: **Train on 2015-2019, Validate on 2020, Test on 2021+**.  \n",
    "- Ensures the model works for **future predictions**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ› ï¸ Python Example: Train-Validation-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (700, 5)\n",
      "Validation Set: (150, 5)\n",
      "Test Set: (150, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset (NBA Wins Prediction)\n",
    "X = np.random.rand(1000, 5)  # 1000 games, 5 features (e.g., 3PT %, Turnovers)\n",
    "y = np.random.randint(0, 2, size=1000)  # 0 = Loss, 1 = Win\n",
    "\n",
    "# Split into Training (70%), Validation (15%), and Test (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training Set: {X_train.shape}\")\n",
    "print(f\"Validation Set: {X_val.shape}\")\n",
    "print(f\"Test Set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… **Output:**  \n",
    "```\n",
    "Training Set: (700, 5)\n",
    "Validation Set: (150, 5)\n",
    "Test Set: (150, 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸš€ Why is a Validation Set Important?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Prevents Overfitting** â†’ Helps the model generalize instead of memorizing training data.  \n",
    "- **Hyperparameter Tuning** â†’ Optimizes parameters like learning rate, tree depth, etc.  \n",
    "- **Improves Final Test Accuracy** â†’ Ensures better real-world performance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ”¥ Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ï¸âƒ£ **A validation set is used to tune the model before final testing.**  \n",
    "2ï¸âƒ£ **It prevents overfitting and helps select the best hyperparameters.**  \n",
    "3ï¸âƒ£ **The test set is only used for final evaluation.**  \n",
    "4ï¸âƒ£ **Common splits: 70%-15%-15% or Cross-Validation for small datasets.**  \n",
    "5ï¸âƒ£ **Essential in sports analytics, finance, and AI applications!**  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
