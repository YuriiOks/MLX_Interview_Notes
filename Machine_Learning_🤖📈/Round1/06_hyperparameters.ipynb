{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6️⃣ Hyperparameters in Machine Learning: Definition & Tuning 🎛️🤖**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **💡 Real-Life Analogy: Tuning an NBA Player’s Shooting Technique 🏀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you're **coaching an NBA player** to improve their shooting. You adjust:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Shot Arc 🎯** (Higher arc = more accuracy, but too high = misses).  \n",
    "- **Release Speed ⏳** (Fast release = harder to block, but may reduce accuracy).  \n",
    "- **Leg Position 🏀** (More stability = better balance, but slower motion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **These settings are like hyperparameters in ML—they control how the model learns but aren’t learned from data!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📌 What Are Hyperparameters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Hyperparameters are settings that control the learning process of a machine learning model.**  \n",
    "✅ They **must be set before training** and are **not learned from the data**.  \n",
    "✅ Examples: **Learning rate, number of layers in a neural network, number of trees in a random forest.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Two Types of Parameters in ML:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type               | What It Does                    | Example                                                    |\n",
    "|--------------------|---------------------------------|------------------------------------------------------------|\n",
    "| **Model Parameters**   | Learned from data 📊             | Weights in Linear Regression, Splits in Decision Trees      |\n",
    "| **Hyperparameters**    | Set before training 🎛️          | Learning Rate, Number of Hidden Layers, K in KNN            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Hyperparameters control how the model trains, while parameters are learned from data!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📊 Examples of Hyperparameters in Different ML Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model                         | Key Hyperparameters                    |\n",
    "|-------------------------------|----------------------------------------|\n",
    "| **Linear Regression**         | Regularization strength (L1, L2)         |\n",
    "| **Decision Tree**             | Tree depth, min samples per leaf         |\n",
    "| **Random Forest**             | Number of trees, max depth               |\n",
    "| **K-Nearest Neighbors (KNN)**   | Number of neighbors (K)                  |\n",
    "| **Neural Networks**           | Learning rate, number of layers, batch size|\n",
    "| **Support Vector Machines (SVM)** | Kernel type, C (penalty), Gamma          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Choosing the right hyperparameters is critical for model performance!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📊 Example: Hyperparameters in Football (Soccer) ⚽**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re building a **machine learning model** to predict **if a player will score in a match**.  \n",
    "- **Model Type:** Decision Tree  \n",
    "- **Training Data:** Shots on target, xG, minutes played."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Key Hyperparameters for Decision Trees:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hyperparameter            | Meaning                           | Impact                   |\n",
    "|---------------------------|-----------------------------------|--------------------------|\n",
    "| **Max Depth**             | Limits how deep the tree grows.   | Prevents overfitting.    |\n",
    "| **Min Samples per Leaf**  | Minimum players per leaf node.    | Reduces model complexity.|\n",
    "| **Criterion**             | Measure of split quality (Gini vs. Entropy). | Affects accuracy. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Example Values:**  \n",
    "- **Max Depth = 5** → Limits tree growth.  \n",
    "- **Min Samples per Leaf = 10** → Prevents splits on very small data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Why is tuning important?**  \n",
    "- If the tree is **too deep**, it **memorizes training data** (overfitting).  \n",
    "- If the tree is **too shallow**, it **misses important patterns** (underfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📊 Example: Hyperparameters in NBA Analytics 🏀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re predicting whether an NBA team will **win or lose** based on:  \n",
    "- **3PT Shooting % 🎯**  \n",
    "- **Turnovers per game 🔄**  \n",
    "- **Defensive efficiency 🏀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Using a Random Forest Model:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hyperparameter                      | Meaning                                       | Impact                                                |\n",
    "|-------------------------------------|-----------------------------------------------|-------------------------------------------------------|\n",
    "| **Number of Trees (n_estimators)**  | How many trees in the forest?                 | More trees = better accuracy, but slower training.    |\n",
    "| **Max Features**                    | How many features to use per tree?            | Less = faster, More = more accurate.                  |\n",
    "| **Max Depth**                       | Maximum depth of trees.                       | Higher depth = risk of overfitting.                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Example Values:**  \n",
    "- **n_estimators = 100** → Uses 100 trees.  \n",
    "- **Max Depth = 10** → Limits tree complexity.  \n",
    "- **Max Features = \"sqrt\"** → Uses square root of features per tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Why does tuning matter?**  \n",
    "- Too many trees = **slow model, little extra accuracy**.  \n",
    "- Too few trees = **low accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🛠️ How Do We Tune Hyperparameters? (Hyperparameter Optimization)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ **Grid Search 🔍**  \n",
    "   - Tries **all possible combinations** of hyperparameters.  \n",
    "   - Works well for small search spaces, but slow for large ones.  \n",
    "2️⃣ **Random Search 🎲**  \n",
    "   - Randomly picks hyperparameters instead of trying every combination.  \n",
    "   - Faster than Grid Search, works well with many parameters.  \n",
    "3️⃣ **Bayesian Optimization 🤖**  \n",
    "   - Uses probability to find the best settings.  \n",
    "   - Faster than Grid Search and **works well on deep learning models**.  \n",
    "4️⃣ **Genetic Algorithms (Evolutionary Search) 🧬**  \n",
    "   - Mimics natural selection to evolve the best hyperparameters.  \n",
    "   - Used in **complex ML models like Neural Networks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🛠️ Python Code: Hyperparameter Tuning with Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset (NBA Wins Prediction)\n",
    "X = np.random.rand(1000, 5)  # 1000 games, 5 features (e.g., 3PT %, Turnovers)\n",
    "y = np.random.randint(0, 2, size=1000)  # 0 = Loss, 1 = Win\n",
    "\n",
    "# Define Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Output Example:**  \n",
    "```\n",
    "Best Hyperparameters: {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 50}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **This means the best-performing model uses:**  \n",
    "- **Max Depth = 20**\n",
    "- **Max Features = \"log2\"**\n",
    "- **Number of Trees = 50**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🚀 Why Are Hyperparameters Important?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **1️⃣ Improve Model Accuracy** → The right settings can **boost prediction performance**.  \n",
    "✅ **2️⃣ Prevent Overfitting** → Tuning **regularization and depth** avoids memorizing noise.  \n",
    "✅ **3️⃣ Optimize Training Speed** → **Too many layers in a neural network = slow model**.  \n",
    "✅ **4️⃣ Balance Bias & Variance** → Prevent **underfitting or overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔥 Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ **Hyperparameters are settings that control the learning process (not learned from data).**  \n",
    "2️⃣ **Examples include learning rate, number of trees, max depth, and regularization.**  \n",
    "3️⃣ **Tuning hyperparameters optimally improves accuracy and prevents overfitting.**  \n",
    "4️⃣ **Common tuning methods: Grid Search, Random Search, Bayesian Optimization.**  \n",
    "5️⃣ **Used in Football (xG models), NBA (win prediction), stock markets, deep learning, and more!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
