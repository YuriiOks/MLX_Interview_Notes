{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9️⃣ Regularization in Machine Learning: Purpose & Techniques 🎛️🤖**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **💡 Real-Life Analogy: Avoiding Overfitting in NBA Player Contracts 🏀💰**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you're an **NBA team manager** offering contracts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **No Regularization** → You give **huge contracts** based on **one amazing season** (overfitting to small data). ❌  \n",
    "- **Too Much Regularization** → You only offer **low contracts**, assuming no player is special (underfitting). ❌  \n",
    "- **Optimal Regularization** → You balance past performance and future potential for **smart contracts**. ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Regularization helps prevent overfitting in ML models, just like NBA teams avoid bad contracts!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📌 What is Regularization?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Regularization is a technique used in machine learning to reduce overfitting by adding a penalty to complex models.**  \n",
    "✅ It ensures that the model **generalizes well** instead of memorizing training data.  \n",
    "✅ **Key Idea:** Simpler models perform better on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Mathematical Definition (Regularized Loss Function):**  \n",
    "$$\n",
    "\\text{Loss} = \\text{Original Loss (MSE/LogLoss)} + \\lambda \\times \\text{Penalty (L1/L2)}\n",
    "$$\n",
    "Where:  \n",
    "- **$ \\lambda $ (lambda)** → Regularization strength (higher = stronger penalty).  \n",
    "- **Penalty** → A term that discourages large coefficients (weights)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Regularization helps control complexity to improve real-world performance!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📊 Example: Regularization in Football (Predicting Player Salaries) ⚽**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Scenario:** You want to predict **player salaries** based on:\n",
    "- **Goals Scored 🎯**  \n",
    "- **Assists 🏆**  \n",
    "- **Pass Accuracy (%) 📊**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Without Regularization:**  \n",
    "- The model **overfits** by assigning **huge weight** to goals scored.  \n",
    "- Example: If a player **scored 20 goals last season**, the model **assumes they will always perform the same**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **With Regularization:**  \n",
    "- The model **penalizes large weights**, making it **less sensitive to outliers**.  \n",
    "- A **balanced weight distribution** ensures the model **considers assists & pass accuracy** as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Final Result:** **A more reliable model that generalizes well to new players!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📊 Example: Regularization in NBA Analytics (Predicting MVP Winners) 🏀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Scenario:** You build a model to predict the **NBA MVP winner** based on:\n",
    "- **Points Per Game (PPG) 🏀**  \n",
    "- **Assists & Rebounds 📊**  \n",
    "- **Team Wins 🏆**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Problem Without Regularization:**  \n",
    "- If **one player (e.g., Russell Westbrook in 2017) had insane stats**, the model **overfits**.  \n",
    "- It assumes **only triple-doubles win MVP**, ignoring other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Regularization Fix:**  \n",
    "- Penalizing **high weights** ensures **more balanced MVP predictions** (e.g., Jokic, Embiid).  \n",
    "- The model considers **team wins & efficiency**, not just raw stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Final Result:** **A more generalizable MVP prediction model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **📌 Types of Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Regularization Type**            | **Mathematical Formulation**            | **Used In**             |\n",
    "|-------------------------------------|-----------------------------------------|-------------------------|\n",
    "| **L1 Regularization (Lasso)**        | $\\lambda \\sum \\|w\\|$                | Feature Selection 📊    |\n",
    "| **L2 Regularization (Ridge)**        | $\\lambda \\sum w^2$                | Preventing Overfitting 🔄|\n",
    "| **Elastic Net (L1 + L2)**            | $\\lambda_1 \\sum \\|w\\| + \\lambda_2 \\sum w^2$ | Combination of both 🏆 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **L1 (Lasso) removes unnecessary features (sparse model).**  \n",
    "✅ **L2 (Ridge) shrinks large coefficients but keeps all features.**  \n",
    "✅ **Elastic Net combines both for better performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🆚 L1 vs. L2 Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                          | L1 (Lasso) ✅                                        | L2 (Ridge) ✅                              |\n",
    "|----------------------------------|------------------------------------------------------|--------------------------------------------|\n",
    "| **Effect on Weights**            | Shrinks some weights to **zero** (feature selection) | Shrinks all weights but **keeps all features** |\n",
    "| **Used for Feature Selection?**  | ✅ Yes                                               | ❌ No                                      |\n",
    "| **Best for Sparse Data?**        | ✅ Yes (removes unimportant features)                | ❌ No                                      |\n",
    "| **Computational Cost**           | 🔵 Faster                                           | 🔴 Slightly slower                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **L1 = Feature selection (removes unimportant stats in NBA).**  \n",
    "✅ **L2 = Avoids large weight swings (better generalization).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🛠️ Python Code: Applying Regularization (L1 & L2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Coefficients: [ 0.08173299 -0.03241665  0.08787832]\n",
      "Lasso Coefficients: [ 0.05639098 -0.         -0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset (NBA Player Stats)\n",
    "X = np.array([[25, 10, 8], [30, 8, 6], [15, 12, 9], [28, 7, 5]])  # [PPG, Assists, Rebounds]\n",
    "y = np.array([1, 1, 0, 1])  # 1 = MVP, 0 = Not MVP\n",
    "\n",
    "# Ridge Regression (L2 Regularization)\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X, y)\n",
    "print(\"Ridge Coefficients:\", ridge.coef_)\n",
    "\n",
    "# Lasso Regression (L1 Regularization)\n",
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X, y)\n",
    "print(\"Lasso Coefficients:\", lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **What Happens?**  \n",
    "- **Ridge (L2)** shrinks large weights but keeps all features.  \n",
    "- **Lasso (L1)** shrinks some coefficients to zero (removing less important features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 **Final Result:** **Regularized coefficients prevent overfitting & improve generalization!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🚀 Applications of Regularization in Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Football (Predicting Player Salaries) ⚽** → Prevents over-reliance on goals scored.  \n",
    "✅ **NBA Analytics (MVP Prediction) 🏀** → Ensures balanced weighting of stats.  \n",
    "✅ **Stock Market Prediction 📈** → Reduces impact of extreme past trends.  \n",
    "✅ **Medical Diagnosis 🏥** → Avoids overfitting to rare diseases.  \n",
    "✅ **Spam Detection 📧** → Eliminates unnecessary features (e.g., email length)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔥 Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ **Regularization prevents overfitting by penalizing large model weights.**  \n",
    "2️⃣ **L1 (Lasso) removes unnecessary features (feature selection).**  \n",
    "3️⃣ **L2 (Ridge) keeps all features but shrinks large weights.**  \n",
    "4️⃣ **Elastic Net combines L1 & L2 for better performance.**  \n",
    "5️⃣ **Used in football, NBA, stock markets, medical AI, and fraud detection!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
