{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction_cell_pbp",
   "metadata": {},
   "source": [
    "# PBPSTATS Data Preprocessing - pbpstats_2024.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7257683_pbp",
   "metadata": {},
   "source": [
    "This notebook preprocesses the NBA play-by-play statistics data from `pbpstats_2024.csv`, which contains detailed event-level data for NBA games. The dataset includes information such as event times, shot attempts, rebounds, fouls, scoring details, and video URLs. \n",
    "\n",
    "The notebook covers the following sections:\n",
    " - Data Loading\n",
    " - Data Description\n",
    " - Missing Values & Data Type Checks\n",
    " - Feature Engineering\n",
    " - Exploratory Data Analysis (EDA)\n",
    " - Data Quality & Anomaly Detection\n",
    " - Next Steps\n",
    "\n",
    "Our goal is to obtain a clean, enriched play-by-play dataset that can later be merged with tracking and shot detail data for comprehensive modeling of game events and the eventual EPV (Expected Possession Value) analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toc_cell_pbp",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e55b22_pbp",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Data Loading & Validation\n",
    "3. Data Description\n",
    "4. Missing Values & Data Types\n",
    "5. Feature Engineering\n",
    "6. Exploratory Data Analysis (EDA)\n",
    "7. Data Quality & Outlier Detection\n",
    "8. Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introduction_detail_pbp",
   "metadata": {},
   "source": [
    "## 1. Introduction <a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pbp_intro_desc",
   "metadata": {},
   "source": [
    "The dataset `pbpstats_2024.csv` contains the following key columns:\n",
    "\n",
    "- **ENDTIME:** End time of the event (in MM:SS format).\n",
    "- **EVENTS:** Description of the event(s) that occurred.\n",
    "- **FG2A:** 2-point field goal attempts.\n",
    "- **FG2M:** 2-point field goals made.\n",
    "- **FG3A:** 3-point field goal attempts.\n",
    "- **FG3M:** 3-point field goals made.\n",
    "- **GAMEDATE:** Date of the game.\n",
    "- **GAMEID:** Unique game identifier.\n",
    "- **NONSHOOTINGFOULSTHATRESULTEDINFTS:** Number of non-shooting fouls resulting in free throws.\n",
    "- **OFFENSIVEREBOUNDS:** Number of offensive rebounds.\n",
    "- **OPPONENT:** Opposing team abbreviation.\n",
    "- **PERIOD:** Game period/quarter.\n",
    "- **SHOOTINGFOULSDRAWN:** Number of shooting fouls drawn.\n",
    "- **STARTSCOREDIFFERENTIAL:** Score differential at the start of the event.\n",
    "- **STARTTIME:** Start time of the event (in MM:SS format).\n",
    "- **STARTTYPE:** Type of event start (e.g., regular, timeout).\n",
    "- **TURNOVERS:** Number of turnovers during the event.\n",
    "- **DESCRIPTION:** Detailed description of the event.\n",
    "- **URL:** Link to video footage of the event.\n",
    "\n",
    "We will inspect, clean, and engineer features from this data to facilitate deeper analysis and later integration with other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended_introduction_epv",
   "metadata": {},
   "source": [
    "## Extended Introduction and EPV Overview\n",
    "\n",
    "This notebook not only cleans the PBPSTATS data but also lays the groundwork for extracting features that feed into an Expected Possession Value (EPV) model. By integrating this dataset with player tracking and shot detail data, we aim to analyze game flow and predict possession outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5442acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Set visualization parameters\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Set logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_libraries_pbp",
   "metadata": {},
   "source": [
    "## 2. Data Loading <a id=\"data-loading\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad054017_pbp",
   "metadata": {},
   "source": [
    "Load the play-by-play data from the CSV file. Ensure that the file is located in the `data/raw/` folder. In this example, we assume the path is `../data/raw/pbpstats_2024.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_pbpstats_data_pbp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for PBPSTATS data\n",
    "file_path = Path('../data/raw/pbpstats_2024.csv')\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "try:\n",
    "    df_pbp = pd.read_csv(file_path)\n",
    "    logging.info(\"PBPSTATS data loaded successfully.\")\n",
    "    logging.info(df_pbp.info())\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading file: {e}\")\n",
    "\n",
    "# Display the first few rows and shape\n",
    "display(df_pbp.head())\n",
    "print('Dataset shape:', df_pbp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert-gamedate_pbp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GAMEDATE column to datetime\n",
    "df_pbp['GAMEDATE'] = pd.to_datetime(df_pbp['GAMEDATE'], errors='coerce')\n",
    "print('GAMEDATE converted; sample:', df_pbp['GAMEDATE'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_description_pbp",
   "metadata": {},
   "source": [
    "## 3. Data Description <a id=\"data-description\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed_data_description",
   "metadata": {},
   "source": [
    "### Detailed Column Descriptions\n",
    "\n",
    "- **ENDTIME:** End time of the event (MM:SS). Used to calculate event duration.\n",
    "- **EVENTS:** Textual event summary; helps in classifying the type of play (e.g. shot, turnover).\n",
    "- **FG2A & FG2M:** Essential for computing 2-point shooting efficiency.\n",
    "- **FG3A & FG3M:** Essential for 3-point efficiency metrics.\n",
    "- **GAMEDATE & GAMEID:** For merging datasets and time-based analysis.\n",
    "- **TURNOVERS:** Indicates possession disruptions impacting team performance.\n",
    "- **URL:** Video link field; missing values are imputed with 'no_url_provided'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced_data_description",
   "metadata": {},
   "source": [
    "### Why These Columns Matter\n",
    "\n",
    "- **ENDTIME & STARTTIME:** Critical for calculating event durations which indicate pace and play intensity.\n",
    "- **FG2A/FG2M/FG3A/FG3M:** Determine shooting efficiency, an essential metric for performance analysis.\n",
    "- **GAMEDATE & GAMEID:** Required for merging datasets and time-based analysis.\n",
    "- **TURNOVERS:** Help quantify decision-making and team control during possessions.\n",
    "- **URL:** Although often missing, these links can support game video validations; missing values are replaced with 'no_url_provided'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing_values_section_pbp",
   "metadata": {},
   "source": [
    "## 4. Missing Values & Data Types <a id=\"missing-values\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced_missing_values",
   "metadata": {},
   "source": [
    "### Handling Missing Data & Data Types\n",
    "\n",
    "Special attention is given to time fields and the URL column. Time fields (`STARTTIME`, `ENDTIME`) are converted to seconds for numerical analysis, while missing URLs are imputed with a consistent placeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing_values_analysis",
   "metadata": {},
   "source": [
    "### Missing Values Analysis\n",
    "\n",
    "Below we summarize missing data as a percentage per column. For example, a high percentage in URL is expected and handled by replacing missing values with 'no_url_provided'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_missing_values_pbp_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the PBPSTATS dataset\n",
    "missing_counts_pbp = df_pbp.isnull().sum()\n",
    "total = len(df_pbp)\n",
    "missing_percent = (missing_counts_pbp/total)*100\n",
    "print('Missing values in each column:')\n",
    "print(missing_counts_pbp)\n",
    "print('\\nMissing percentages in each column:')\n",
    "print(missing_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_types_pbp",
   "metadata": {},
   "source": [
    "### 4.2 Display Current Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display_data_types_pbp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the current data types for the PBPSTATS dataset\n",
    "print('\\nData types:')\n",
    "print(df_pbp.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps_pbp",
   "metadata": {},
   "source": [
    "#### **Next Steps for Data Types & Missing Values:**\n",
    "- Convert time columns such as `ENDTIME` and `STARTTIME` to datetime objects or to seconds (numerical format) for easier time-based computations.\n",
    "- Evaluate and impute (or drop) any columns with significant missing values.\n",
    "- Ensure categorical columns (e.g., `STARTTYPE`, `DESCRIPTION`) are correctly formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_engineering_pbp",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering <a id=\"feature-engineering\"></a>\n",
    "\n",
    "In this section, we derive new features from the raw play-by-play data to capture key aspects of game events. The planned steps include:\n",
    "\n",
    "1. **Time Features:**\n",
    "   - Convert `STARTTIME` and `ENDTIME` from MM:SS to seconds.\n",
    "   - Derive **EVENT_DURATION** as the absolute difference between `ENDTIME` and `STARTTIME` (in seconds).\n",
    "\n",
    "2. **Categorical Features:**\n",
    "   - Parse the `EVENTS` and `DESCRIPTION` columns to extract common event types (e.g., shot attempt, turnover, rebound).\n",
    "   - Create dummy variables if necessary to indicate the presence of key event types.\n",
    "\n",
    "3. **Game State Features:**\n",
    "   - Compute **SCORE_DIFF** as the difference in scores at the start of each event.\n",
    "   - Calculate **SCORE_CHANGE** as the difference in scores between the start and end of each event.\n",
    "\n",
    "4. **URL Handling:**\n",
    "   - Replace missing URLs with a consistent placeholder (e.g., 'no_url_provided')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering_pbp_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to convert time strings in MM:SS to seconds\n",
    "def time_str_to_seconds(time_str):\n",
    "    \"\"\"\n",
    "    Convert a time string in MM:SS format to seconds.\n",
    "    Returns 0 in case of failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        minutes, seconds = time_str.split(':')\n",
    "        return int(minutes) * 60 + float(seconds)\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "# Convert STARTTIME and ENDTIME to seconds\n",
    "df_pbp['STARTTIME_SEC'] = df_pbp['STARTTIME'].apply(time_str_to_seconds)\n",
    "df_pbp['ENDTIME_SEC'] = df_pbp['ENDTIME'].apply(time_str_to_seconds)\n",
    "\n",
    "# Compute event duration as the absolute difference\n",
    "df_pbp['EVENT_DURATION'] = abs(df_pbp['ENDTIME_SEC'] - df_pbp['STARTTIME_SEC'])\n",
    "\n",
    "# Display a sample of the new features\n",
    "display(df_pbp[['STARTTIME', 'ENDTIME', 'STARTTIME_SEC', 'ENDTIME_SEC', 'EVENT_DURATION']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "calculate_shooting_percentages",
   "metadata": {},
   "source": [
    "### 5.2 Calculating Shooting Percentages\n",
    "\n",
    "Calculate 2-point and 3-point shooting percentages with division-by-zero handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate_shooting_percentages_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate shooting percentages with division-by-zero handling\n",
    "df_pbp['FG2_PCT'] = df_pbp.apply(lambda r: r['FG2M'] / r['FG2A'] if r['FG2A'] > 0 else 0, axis=1)\n",
    "df_pbp['FG3_PCT'] = df_pbp.apply(lambda r: r['FG3M'] / r['FG3A'] if r['FG3A'] > 0 else 0, axis=1)\n",
    "print('Shooting percentages computed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "game_state_features",
   "metadata": {},
   "source": [
    "### 5.3 Game State Features\n",
    "\n",
    "- **SCORE_DIFF:** Use the `STARTSCOREDIFFERENTIAL` column (if available) to indicate the score difference at the start of the event.\n",
    "- **SCORE_CHANGE:** Compute the change in score during the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67db0075_pbp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate score differential and score change\n",
    "df_pbp['SCORE_DIFF'] = df_pbp['STARTSCOREDIFFERENTIAL']\n",
    "df_pbp['SCORE_CHANGE'] = df_pbp['SCORE_DIFF'] - df_pbp['STARTSCOREDIFFERENTIAL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "url_handling_pbp",
   "metadata": {},
   "source": [
    "### 5.4 URL Handling\n",
    "\n",
    "Replace missing URL values with a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd35a6e_pbp",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pbp['URL'] = df_pbp['URL'].fillna('no_url_provided')\n",
    "print('Missing URL values have been handled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda_section_pbp",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis (EDA) <a id=\"eda\"></a>\n",
    "\n",
    "## 6.1 Distribution Analysis\n",
    "We examine the distribution of key metrics using histograms with KDE overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_summary_pbp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics for key numerical features in the PBPSTATS dataset\n",
    "pbp_summary_stats = df_pbp.describe()\n",
    "print(\"Summary Statistics for PBPSTATS Key Features:\")\n",
    "display(pbp_summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_first_game_analysis",
   "metadata": {},
   "source": [
    "### 6.1.1 First Game Detailed Analysis\n",
    "\n",
    "In this section, we extract the data for the first game (based on the smallest GAMEID) and analyze key features. We focus on:\n",
    "- **Event Duration:** How long events last in this game.\n",
    "- **Shooting Percentages:** Distribution of FG2_PCT and FG3_PCT.\n",
    "- **Turnovers:** Frequency of turnovers as an indicator of possession control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first_game_filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the first game based on the smallest GAMEID\n",
    "first_game_id = df_pbp['GAMEID'].min()\n",
    "print(f\"First GAMEID: {first_game_id}\")\n",
    "\n",
    "# Filter the dataframe for the first game\n",
    "df_first_game = df_pbp[df_pbp['GAMEID'] == first_game_id]\n",
    "print(f\"First game shape: {df_first_game.shape}\")\n",
    "display(df_first_game.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first_game_analysis",
   "metadata": {},
   "source": [
    "### 6.1.2 Analysis of the First Game\n",
    "\n",
    "Let's analyze some key features for the first game:\n",
    "- **Event Duration Distribution**\n",
    "- **Shooting Percentages (FG2_PCT & FG3_PCT)**\n",
    "- **Turnover Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first_game_plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Histogram for EVENT_DURATION in the first game\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_first_game['EVENT_DURATION'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('EVENT_DURATION Distribution - First Game')\n",
    "\n",
    "# Histogram for FG2_PCT in the first game\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_first_game['FG2_PCT'], bins=20, kde=True, color='salmon')\n",
    "plt.title('FG2 Percentage - First Game')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display a count plot for TURNOVERS in the first game\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='TURNOVERS', data=df_first_game, palette='viridis')\n",
    "plt.title('Turnover Counts - First Game')\n",
    "plt.xlabel('Turnovers')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random_games_analysis",
   "metadata": {},
   "source": [
    "### 6.1.3 Random Games Comparison\n",
    "\n",
    "Next, we randomly select 3–5 distinct games from the dataset and analyze key features to compare game dynamics. For these games, we will look at:\n",
    "- **Event Duration Distribution**\n",
    "- **Scoring and Turnover Metrics**\n",
    "- **Comparative Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random_games_filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique game IDs\n",
    "unique_games = df_pbp['GAMEID'].unique()\n",
    "\n",
    "# Randomly select 5 games (if available)\n",
    "np.random.seed(42)\n",
    "selected_game_ids = np.random.choice(unique_games, size=5, replace=False)\n",
    "print(f\"Selected Game IDs for random analysis: {selected_game_ids}\")\n",
    "\n",
    "# Create a dataframe for the selected games\n",
    "df_random_games = df_pbp[df_pbp['GAMEID'].isin(selected_game_ids)]\n",
    "print(f\"Random games dataframe shape: {df_random_games.shape}\")\n",
    "display(df_random_games.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random_games_plots",
   "metadata": {},
   "source": [
    "### 6.1.4 Analysis of Random Games\n",
    "\n",
    "For the selected games, we create multi-panel plots to compare key metrics across games. We focus on EVENT_DURATION and scoring differentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random_games_plots_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a boxplot of EVENT_DURATION grouped by GAMEID\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='GAMEID', y='EVENT_DURATION', data=df_random_games, palette='Set2')\n",
    "plt.title('Event Duration by GAMEID (Random Games)')\n",
    "plt.xlabel('GAMEID')\n",
    "plt.ylabel('EVENT_DURATION (seconds)')\n",
    "plt.show()\n",
    "\n",
    "# Create a bar plot of average FG2_PCT for each game\n",
    "avg_fg2_pct = df_random_games.groupby('GAMEID')['FG2_PCT'].mean().reset_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='GAMEID', y='FG2_PCT', data=avg_fg2_pct, palette='Set1')\n",
    "plt.title('Average 2-Point FG Percentage by GAMEID (Random Games)')\n",
    "plt.xlabel('GAMEID')\n",
    "plt.ylabel('Average FG2_PCT')\n",
    "plt.show()\n",
    "\n",
    "# Display summary statistics for the selected games\n",
    "print('Summary Statistics for Selected Games:')\n",
    "display(df_random_games.groupby('GAMEID').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1067e1",
   "metadata": {},
   "source": [
    "The analysis of random games provides insights into the variability of game dynamics, event durations, and scoring patterns. This comparison helps identify trends and outliers in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb44ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Global visualization settings and color palette\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "colors = {\n",
    "    'primary': '#1f77b4',\n",
    "    'secondary': '#ff7f0e',\n",
    "    'highlight': '#2ca02c'\n",
    "}\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (12, 6),\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.grid': True\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f0fa6",
   "metadata": {},
   "source": [
    "## 6.2 Correlation Heatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6594739e",
   "metadata": {},
   "source": [
    "We create a correlation heatmap to visualize the relationships between numerical features. This analysis helps identify potential multicollinearity and relationships between variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c141f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['EVENT_DURATION', 'FG2_PCT', 'FG3_PCT', 'PERIOD', 'STARTSCOREDIFFERENTIAL']\n",
    "correlation_matrix = df_pbp[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a8271",
   "metadata": {},
   "source": [
    "### Overview\n",
    "The correlation matrix shows relationships between five key features:\n",
    "- EVENT_DURATION\n",
    "- FG2_PCT (2-point Field Goal Percentage)\n",
    "- FG3_PCT (3-point Field Goal Percentage)\n",
    "- PERIOD\n",
    "- STARTSCOREDIFFERENTIAL\n",
    "\n",
    "### Key Correlations\n",
    "\n",
    "#### Strong Correlations (|r| > 0.5)\n",
    "- None observed - all correlations are relatively weak (|r| < 0.2)\n",
    "\n",
    "#### Moderate Correlations (0.2 < |r| < 0.5)\n",
    "- None observed\n",
    "\n",
    "#### Weak Correlations (|r| < 0.2)\n",
    "1. **FG2_PCT and FG3_PCT** (r = -0.16)\n",
    "   - Slight negative correlation\n",
    "   - Suggests that when 2-point shooting percentage is higher, 3-point percentage tends to be slightly lower\n",
    "   - Could indicate strategic trade-offs in shot selection\n",
    "\n",
    "2. **EVENT_DURATION and FG2_PCT** (r = -0.078)\n",
    "   - Very weak negative correlation\n",
    "   - Longer events are slightly associated with lower 2-point shooting percentages\n",
    "   - May reflect defensive pressure leading to longer possessions\n",
    "\n",
    "3. **Other Correlations** (all |r| < 0.05)\n",
    "   - EVENT_DURATION and FG3_PCT: -0.035\n",
    "   - PERIOD and other variables: all near 0.02\n",
    "   - STARTSCOREDIFFERENTIAL and other variables: all near 0.02 or lower\n",
    "\n",
    "### Insights\n",
    "\n",
    "1. **Independence of Features**\n",
    "   - Most features show very weak correlations\n",
    "   - Suggests these metrics capture different aspects of game play\n",
    "   - Variables are largely independent of each other\n",
    "\n",
    "2. **Shot Selection**\n",
    "   - The weak negative correlation between FG2_PCT and FG3_PCT might reflect:\n",
    "     - Team shooting strategies\n",
    "     - Defensive adjustments\n",
    "     - Player specialization\n",
    "\n",
    "3. **Game Flow**\n",
    "   - PERIOD and STARTSCOREDIFFERENTIAL showing minimal correlations indicates:\n",
    "     - Consistent play patterns across quarters\n",
    "     - Score differential doesn't strongly influence other metrics\n",
    "     - Game dynamics remain relatively stable regardless of game situation\n",
    "\n",
    "4. **Event Duration**\n",
    "   - Weak correlations with shooting percentages suggest:\n",
    "     - Play duration isn't strongly tied to shooting success\n",
    "     - Teams maintain consistent efficiency regardless of possession length\n",
    "\n",
    "### Implications for Analysis\n",
    "1. **Feature Selection**\n",
    "   - Low correlations suggest these features provide unique information\n",
    "   - All features should be retained for modeling\n",
    "   - No need to address multicollinearity\n",
    "\n",
    "2. **Modeling Considerations**\n",
    "   - May need to engineer interaction terms\n",
    "   - Consider non-linear relationships\n",
    "   - Look for conditional dependencies not captured by linear correlation\n",
    "\n",
    "3. **Future Investigation**\n",
    "   - Consider additional features that might show stronger relationships\n",
    "   - Examine temporal patterns within games\n",
    "   - Investigate team-specific patterns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f47ee6",
   "metadata": {},
   "source": [
    "## 6.3 Additional Graphs: Boxplot & Scatter Plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469288cc",
   "metadata": {},
   "source": [
    "We create a boxplot for EVENT_DURATION to highlight outliers and a scatter plot for FG2A vs FG2M to inspect the relationship between shot attempts and makes. These visualizations provide additional insights into the data distribution and relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# EVENT_DURATION distribution with KDE\n",
    "sns.histplot(data=df_pbp, x='EVENT_DURATION', kde=True, ax=ax1, color=colors['primary'])\n",
    "ax1.set_title('Event Duration Distribution')\n",
    "\n",
    "# FG2_PCT distribution with KDE\n",
    "sns.histplot(data=df_pbp, x='FG2_PCT', kde=True, ax=ax2, color=colors['secondary'])\n",
    "ax2.set_title('2-Point FG Percentage')\n",
    "\n",
    "# FG3_PCT distribution with KDE\n",
    "sns.histplot(data=df_pbp, x='FG3_PCT', kde=True, ax=ax3, color=colors['highlight'])\n",
    "ax3.set_title('3-Point FG Percentage')\n",
    "\n",
    "# Events count by PERIOD as a bar plot\n",
    "df_pbp['PERIOD'].value_counts().sort_index().plot(kind='bar', ax=ax4, color=colors['primary'])\n",
    "ax4.set_title('Events by Period')\n",
    "ax4.set_xlabel('Period')\n",
    "ax4.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d687c81",
   "metadata": {},
   "source": [
    "| **Event Duration Distribution** <br><br> - Right-skewed distribution with a long tail from 0 to ~60 seconds, peaking between 10–20 seconds. <br> - Implies most plays resolve within 20 seconds with few extended events (over 30s).  | **2-Point FG Percentage Distribution** <br><br> - Trimodal pattern with a large spike at 0.0 (missed shots), a moderate peak around 0.5–0.6, and a spike at 1.0 (perfect shooting). <br> - Indicates possessions often end either in misses or in highly efficient shots, with fewer average attempts.  |\n",
    "|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **3-Point FG Percentage Distribution** <br><br> - Similar to the 2-point pattern but more extreme: pronounced spikes at 0 and 1 with little middle-range variation. <br> - Emphasizes an all-or-nothing shooting outcome for 3-point attempts.           | **Events by Period** <br><br> - Regular quarters (1–4) maintain consistent event counts (~60,000 each), while overtime periods (5–6) have dramatically fewer events. <br> - Reflects a steady game pace in regulation and distinct OT dynamics.  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for EVENT_DURATION to highlight outliers\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=df_pbp['EVENT_DURATION'], color='lightgreen')\n",
    "plt.title('Boxplot of EVENT_DURATION')\n",
    "\n",
    "# Scatter plot for FG2A vs FG2M to inspect relationship between shot attempts and makes\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(x='FG2A', y='FG2M', data=df_pbp, alpha=0.5, color='navy')\n",
    "plt.title('Scatter Plot: FG2A vs FG2M')\n",
    "plt.xlabel('2-Point Field Goal Attempts')\n",
    "plt.ylabel('2-Point Field Goal Makes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2962d58",
   "metadata": {},
   "source": [
    "| **Boxplot of EVENT_DURATION** | **Scatter Plot: FG2A vs FG2M (2-Point FG Attempts vs Makes)** |\n",
    "|------------------------------|---------------------------------------------------------------|\n",
    "| **Graph Type:** Boxplot of event durations.  <br> **Key Observations:** <br> - Median around 15 seconds <br> - IQR approximately 10–20 seconds <br> - Whiskers extend to ~5–30 seconds <br> - Numerous outliers beyond 30 seconds (some reaching 60+ seconds)  <br><br> **Statistical Insights:** <br> - Most events cluster between 10–20 seconds <br> - Median aligns with typical play duration (~15 sec), reflecting the NBA shot clock context  <br><br> **Outlier Analysis:** <br> - Upper outliers appear systematically, likely representing timeouts, free throw sequences, review periods, or end-of-quarter situations. | **Graph Type:** Scatter plot of 2-Point Field Goal Attempts (FG2A) vs Makes (FG2M).  <br> **Key Observations:** <br> - Points appear at specific integer coordinates <br> - Clear upper boundary (makes cannot exceed attempts) <br> - Three discrete levels corresponding to shot outcomes: 0, 1, and 2 makes  <br><br> **Pattern Analysis:** <br> - Zero makes are most common (attempts from 0 to 7) <br> - One make spans scenarios with 1–7 attempts <br> - Two makes are rarer, possible only with 2+ attempts  <br><br> **Efficiency Insights:** <br> - Perfect shooting efficiency (points along the diagonal) is rare <br> - Most data points lie below optimal efficiency, implying defensive impact on scoring. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_quality_pbp",
   "metadata": {},
   "source": [
    "## 7. Data Quality & Anomaly Detection <a id=\"data-quality\"></a>\n",
    "\n",
    "### 7.1 Initial Data Quality Assessment\n",
    "First, we perform a comprehensive check of data quality metrics including missing values, duplicates, and basic validation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_quality_assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_quality_assessment(df):\n",
    "    quality_metrics = {\n",
    "        'total_rows': len(df),\n",
    "        'missing_values': df.isnull().sum(),\n",
    "        'duplicate_rows': len(df[df.duplicated()]),\n",
    "        'memory_usage': df.memory_usage().sum() / 1024**2  # in MB\n",
    "    }\n",
    "    return quality_metrics\n",
    "\n",
    "# Run initial assessment\n",
    "quality_results = initial_quality_assessment(df_pbp)\n",
    "print(\"Data Quality Metrics:\")\n",
    "for metric, value in quality_results.items():\n",
    "    if metric != 'missing_values':\n",
    "        print(f\"{metric}: {value}\")\n",
    "print(\"\\nMissing Values by Column:\")\n",
    "print(quality_results['missing_values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced_data_quality",
   "metadata": {},
   "source": [
    "### 7.2 Feature-Specific Validation\n",
    "Validate business rules and logical constraints for specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate_feature_rules",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_feature_rules(df):\n",
    "    validation_results = {\n",
    "        'valid_periods': df['PERIOD'].between(1, 6).all(),\n",
    "        'valid_shots': (df['FG2M'] <= df['FG2A']).all() and (df['FG3M'] <= df['FG3A']).all(),\n",
    "        'valid_times': (df['ENDTIME_SEC'] > df['STARTTIME_SEC']).all(),\n",
    "        'valid_scores': (df['STARTSCOREDIFFERENTIAL'].abs() <= 50).all\n",
    "    }\n",
    "    return validation_results\n",
    "\n",
    "# Run validation checks\n",
    "validation_results = validate_feature_rules(df_pbp)\n",
    "print(\"Feature Validation Results:\")\n",
    "for rule, passed in validation_results.items():\n",
    "    print(f\"{rule}: {'✓' if passed else '✗'}\")\n",
    "\n",
    "# Identify problematic records\n",
    "invalid_shots = df_pbp[~((df_pbp['FG2M'] <= df_pbp['FG2A']) & (df_pbp['FG3M'] <= df_pbp['FG3A']))]\n",
    "if len(invalid_shots) > 0:\n",
    "    print(\"\\nFound invalid shot records:\")\n",
    "    display(invalid_shots[['GAMEID', 'FG2A', 'FG2M', 'FG3A', 'FG3M']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdd1d9",
   "metadata": {},
   "source": [
    "### 1. Passing Validations\n",
    "- **Period Values** (✓): All periods are within valid range (1-6)\n",
    "- **Shot Attempts** (✓): All FG2M/FG3M are less than or equal to FG2A/FG3A\n",
    "- **Score Differentials** (✓): All score differentials are within reasonable bounds (≤ 50)\n",
    "\n",
    "### 2. Failed Validation\n",
    "- **Time Sequence** (✗): Some ENDTIME_SEC values are not greater than STARTTIME_SEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced_data_quality",
   "metadata": {},
   "source": [
    "### 7.3 Comprehensive Outlier Detection\n",
    "Analyze outliers across all numerical features using the IQR method and additional statistical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d1c4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr_pbp(df, feature):\n",
    "    \"\"\"\n",
    "    Detect outliers using the IQR method.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        feature (str): Column name to analyze\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (outliers DataFrame, lower bound, upper bound)\n",
    "    \"\"\"\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_all_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_features(df):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of all numerical features.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results for each feature\n",
    "    \"\"\"\n",
    "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    outlier_summary = {}\n",
    "    \n",
    "    for feature in numerical_features:\n",
    "        outliers, lower, upper = detect_outliers_iqr_pbp(df, feature)\n",
    "        stats = df[feature].describe()\n",
    "        outlier_summary[feature] = {\n",
    "            'count': len(outliers),\n",
    "            'percentage': (len(outliers)/len(df))*100,\n",
    "            'bounds': (lower, upper),\n",
    "            'skewness': df[feature].skew(),\n",
    "            'kurtosis': df[feature].kurtosis(),\n",
    "            'stats': stats\n",
    "        }\n",
    "    return outlier_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "862ea5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(df, feature, outlier_bounds=None):\n",
    "    \"\"\"\n",
    "    Plot distribution of a feature with outlier bounds if provided.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        feature (str): Feature to plot\n",
    "        outlier_bounds (tuple): Optional (lower, upper) bounds for outliers\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[feature], kde=True)\n",
    "    if outlier_bounds:\n",
    "        plt.axvline(x=outlier_bounds[0], color='r', linestyle='--', label='Lower bound')\n",
    "        plt.axvline(x=outlier_bounds[1], color='r', linestyle='--', label='Upper bound')\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb8c7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distributions(df, outlier_analysis, features_per_row=3):\n",
    "    \"\"\"\n",
    "    Plot multiple feature distributions in a grid of subplots.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        outlier_analysis (dict): Dictionary containing outlier analysis results\n",
    "        features_per_row (int): Number of plots per row\n",
    "    \"\"\"\n",
    "    # Calculate number of rows needed\n",
    "    n_features = len(outlier_analysis)\n",
    "    n_rows = (n_features + features_per_row - 1) // features_per_row\n",
    "    \n",
    "    # Create figure and subplots\n",
    "    fig, axes = plt.subplots(n_rows, features_per_row, \n",
    "                            figsize=(15, 5*n_rows),\n",
    "                            squeeze=False)\n",
    "    \n",
    "    # Flatten axes for easier iteration\n",
    "    axes_flat = axes.flatten()\n",
    "\n",
    "    # Plot each feature\n",
    "    for idx, (feature, metrics) in enumerate(outlier_analysis.items()):\n",
    "        ax = axes_flat[idx]\n",
    "        \n",
    "        # Plot histogram with KDE\n",
    "        sns.histplot(df[feature], kde=True, ax=ax)\n",
    "        \n",
    "        # Add outlier bounds\n",
    "        if 'bounds' in metrics:\n",
    "            lower, upper = metrics['bounds']\n",
    "            ax.axvline(x=lower, color='r', linestyle='--', label='Lower bound')\n",
    "            ax.axvline(x=upper, color='r', linestyle='--', label='Upper bound')\n",
    "        \n",
    "        # Add title with statistics\n",
    "        ax.set_title(f'{feature}\\nOutliers: {metrics[\"percentage\"]:.1f}%\\n' +\n",
    "                    f'Skew: {metrics[\"skewness\"]:.2f}')\n",
    "        \n",
    "        # Rotate x-axis labels if needed\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add legend\n",
    "        ax.legend()\n",
    "    \n",
    "    # Remove empty subplots if any\n",
    "    for idx in range(len(outlier_analysis), len(axes_flat)):\n",
    "        fig.delaxes(axes_flat[idx])\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "def run_feature_analysis(df):\n",
    "    \"\"\"\n",
    "    Run complete feature analysis with compact visualization.\n",
    "    \"\"\"\n",
    "    # Run analysis\n",
    "    outlier_analysis = analyze_all_features(df)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = plot_feature_distributions(df, outlier_analysis)\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(\"\\nDetailed Feature Analysis:\")\n",
    "    print(\"=\"*80)\n",
    "    for feature, metrics in outlier_analysis.items():\n",
    "        print(f\"\\nFeature: {feature}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        print(f\"Outliers: {metrics['count']} ({metrics['percentage']:.2f}%)\")\n",
    "        print(f\"Bounds: {metrics['bounds']}\")\n",
    "        print(f\"Skewness: {metrics['skewness']:.2f}\")\n",
    "        print(f\"Kurtosis: {metrics['kurtosis']:.2f}\")\n",
    "        if 'stats' in metrics:\n",
    "            print(\"\\nDescriptive Statistics:\")\n",
    "            print(metrics['stats'])\n",
    "    \n",
    "    return outlier_analysis, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis\n",
    "outlier_analysis, fig = run_feature_analysis(df_pbp)\n",
    "\n",
    "# Save the figure if needed\n",
    "fig.savefig('feature_analysis.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66288592",
   "metadata": {},
   "source": [
    "# Analysis of Feature Distributions and Outliers\n",
    "\n",
    "## Shot-Related Features\n",
    "\n",
    "### 1. FG2A (2-Point Field Goal Attempts)\n",
    "- **Distribution**: Discrete, concentrated at 0-4 attempts\n",
    "- **Outliers**: 1.5% of data\n",
    "- **Skewness**: 1.25 (right-skewed)\n",
    "- **Pattern**: Most possessions have 0-1 attempts, rare cases of 4+ attempts\n",
    "\n",
    "### 2. FG2M (2-Point Field Goals Made)\n",
    "- **Distribution**: Highly concentrated at 0-1 makes\n",
    "- **Outliers**: 22.5% (relatively high)\n",
    "- **Skewness**: 1.33 (right-skewed)\n",
    "- **Pattern**: Strong binary pattern (make/miss)\n",
    "\n",
    "### 3. FG3A/FG3M (3-Point Attempts/Makes)\n",
    "- **Distribution**: Similar to FG2A/M but more extreme\n",
    "- **Outliers**: 0.3% (very few)\n",
    "- **Skewness**: 1.12/2.86 respectively\n",
    "- **Pattern**: More concentrated at 0, fewer multiple-attempt possessions\n",
    "\n",
    "## Game Flow Features\n",
    "\n",
    "### 4. PERIOD\n",
    "- **Distribution**: Uniform across periods 1-4\n",
    "- **Outliers**: 0.0% (as expected)\n",
    "- **Pattern**: Clear peaks for each quarter, minimal overtime periods\n",
    "\n",
    "### 5. STARTSCOREDIFFERENTIAL\n",
    "- **Distribution**: Normal/bell-shaped\n",
    "- **Outliers**: 3.8%\n",
    "- **Skewness**: -0.02 (nearly symmetric)\n",
    "- **Range**: Mostly within ±25 points\n",
    "\n",
    "### 6. EVENT_DURATION\n",
    "- **Distribution**: Right-skewed\n",
    "- **Outliers**: 1.1%\n",
    "- **Pattern**: \n",
    "  - Peak around 15-20 seconds\n",
    "  - Long tail extending to 60 seconds\n",
    "  - Aligns with shot clock duration\n",
    "\n",
    "## Foul-Related Features\n",
    "\n",
    "### 7. NONSHOOTINGFOULSTHATRESULTEDINFTS\n",
    "- **Distribution**: Highly skewed\n",
    "- **Outliers**: 3.8%\n",
    "- **Pattern**: Majority at 0, sharp decline\n",
    "\n",
    "### 8. SHOOTINGFOULSDRAWN\n",
    "- **Distribution**: Right-skewed\n",
    "- **Outliers**: 19.8%\n",
    "- **Pattern**: Most common at 0-1, rare above 2\n",
    "\n",
    "## Time-Related Features\n",
    "\n",
    "### 9. STARTTIME_SEC/ENDTIME_SEC\n",
    "- **Distribution**: Relatively uniform within game periods\n",
    "- **Outliers**: 0.0%\n",
    "- **Pattern**: Clear period boundaries at multiples of 720 seconds\n",
    "\n",
    "## Additional Metrics\n",
    "\n",
    "### 10. OFFENSIVEREBOUNDS\n",
    "- **Distribution**: Right-skewed\n",
    "- **Outliers**: 24.5%\n",
    "- **Pattern**: Most possessions have 0-1 rebounds\n",
    "\n",
    "### 11. TURNOVERS\n",
    "- **Distribution**: Highly right-skewed\n",
    "- **Outliers**: 10.7%\n",
    "- **Pattern**: Majority at 0, rapid decline\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "1. **Shot Distributions**:\n",
    "   - Most possessions involve 0-1 shot attempts\n",
    "   - Higher variance in 2-point attempts vs 3-point\n",
    "   - Clear make/miss patterns align with expected basketball statistics\n",
    "\n",
    "2. **Game Flow**:\n",
    "   - Score differentials follow normal distribution\n",
    "   - Event durations align with shot clock expectations\n",
    "   - Clear period structure with expected frequency drops in overtime\n",
    "\n",
    "3. **Outlier Patterns**:\n",
    "   - Highest outlier percentages in:\n",
    "     - FG2M (22.5%)\n",
    "     - OFFENSIVEREBOUNDS (24.5%)\n",
    "     - SHOOTINGFOULSDRAWN (19.8%)\n",
    "   - Lowest in:\n",
    "     - PERIOD (0.0%)\n",
    "     - FG3A (0.3%)\n",
    "     - TIME-related features (0.0%)\n",
    "\n",
    "4. **Data Quality Implications**:\n",
    "   - Most distributions follow expected basketball patterns\n",
    "   - Outliers generally represent legitimate game situations\n",
    "   - Time-related features show good structural integrity\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "1. **Outlier Handling**:\n",
    "   - Keep most outliers as they represent valid game situations\n",
    "   - Focus validation on extreme cases in:\n",
    "     - SHOOTINGFOULSDRAWN > 2\n",
    "     - EVENT_DURATION > 40 seconds\n",
    "     - Multiple shot attempts in single possession\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Consider creating composite features for:\n",
    "     - Shooting efficiency\n",
    "     - Possession outcome classification\n",
    "     - Time management metrics\n",
    "\n",
    "3. **Data Quality**:\n",
    "   - Implement range validation for score differentials\n",
    "   - Verify time sequence integrity\n",
    "   - Cross-validate multiple shot attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handle-missing-url_pbp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing URL values with a placeholder string\n",
    "df_pbp['URL'] = df_pbp['URL'].fillna('no_url_provided')\n",
    "print('Missing URL values have been handled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_save_clean_data",
   "metadata": {},
   "source": [
    "## 8. Next Steps & Save Cleaned Data\n",
    "\n",
    "After further processing and EDA, export the refined dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_clean_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the refined PBPSTATS dataset to a CSV file\n",
    "output_path = Path('../data/processed/refined_pbpstats_2024.csv')\n",
    "df_pbp.to_csv(output_path, index=False)\n",
    "logging.info(f\"Refined PBPSTATS data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_thoughts_pbp",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "Our comprehensive preprocessing and EDA have prepared a clean, enriched play-by-play dataset. The next phase will focus on building predictive models that leverage these insights to forecast game events and contribute to our overall EPV model for NBA games."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "nav_menu": {},
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
