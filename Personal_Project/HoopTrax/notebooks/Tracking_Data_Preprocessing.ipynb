{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction_cell",
   "metadata": {},
   "source": [
    "# Tracking Data Preprocessing - datanba_2024.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7257683",
   "metadata": {},
   "source": [
    "\n",
    "This notebook preprocesses the NBA tracking data from `datanba_2024.csv`, which contains high-frequency (25 Hz) positional data for NBA players and the ball. The notebook covers data loading, description, missing values and data type checks, feature engineering, exploratory data analysis (EDA), and data quality & anomaly detection. \n",
    "\n",
    "The final goal is to obtain a clean and enriched dataset ready for advanced modeling (e.g., using LSTMs, Transformers, or Graph Neural Networks) to predict player trajectories and analyze team strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toc_cell",
   "metadata": {},
   "source": [
    "## Table of Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e55b22",
   "metadata": {},
   "source": [
    "1. [Introduction](#introduction)\n",
    "2. [Data Loading](#data-loading)\n",
    "3. [Data Description](#data-description)\n",
    "4. [Missing Values & Data Types](#missing-values)\n",
    "5. [Feature Engineering](#feature-engineering)\n",
    "6. [Exploratory Data Analysis (EDA)](#eda)\n",
    "7. [Data Quality & Anomaly Detection](#data-quality)\n",
    "8. [Next Steps](#next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introduction_detail",
   "metadata": {},
   "source": [
    "## 1. Introduction <a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fb81e",
   "metadata": {},
   "source": [
    "The dataset `datanba_2024.csv` contains the following key columns:\n",
    "\n",
    "- **evt:** Event identifier (integer).\n",
    "- **wallclk:** Wall clock timestamp (string in ISO format).\n",
    "- **cl:** In-game clock (string, e.g., '12:00').\n",
    "- **de:** Event description (string).\n",
    "- **locX, locY:** Spatial coordinates on the court (integers).\n",
    "- **opt1, opt2, opt3, opt4:** Optional fields with additional numerical data.\n",
    "- **mtype, etype:** Codes representing event types (integers).\n",
    "- **opid:** Optional event identifier (float, many missing values).\n",
    "- **tid:** Team identifier (integer).\n",
    "- **pid:** Player identifier (integer).\n",
    "- **hs, vs:** Home and visitor scores (integers).\n",
    "- **epid:** Event period identifier (float).\n",
    "- **oftid:** Offensive team identifier (integer).\n",
    "- **ord:** Order of the event in the game (integer).\n",
    "- **pts:** Points scored in the event (integer).\n",
    "- **PERIOD:** Game period/quarter (integer).\n",
    "- **GAME_ID:** Unique game identifier (integer).\n",
    "\n",
    "We will inspect, clean, and engineer features from this data before integrating it with other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b82b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Set visualization parameters\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "## 2. Data Loading <a id=\"data-loading\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad054017",
   "metadata": {},
   "source": [
    "\n",
    "Load the tracking data from the CSV file. Ensure that the file is located in the `data/raw/` folder. In this example, we assume the path is `../data/raw/datanba_2024.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '../data/raw/datanba_2024.csv'\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "try:\n",
    "    df_tracking = pd.read_csv(file_path)\n",
    "    print('Tracking data loaded successfully.')\n",
    "except Exception as e:\n",
    "    print(f'Error loading file: {e}')\n",
    "\n",
    "# Display the first few rows\n",
    "display(df_tracking.head())\n",
    "\n",
    "# Print the dataset shape\n",
    "print('Dataset shape:', df_tracking.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_description",
   "metadata": {},
   "source": [
    "## 3. Data Description <a id=\"data-description\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda330e",
   "metadata": {},
   "source": [
    "\n",
    "Below is an overview of the columns in this dataset:\n",
    "\n",
    "- **evt:** Event identifier.\n",
    "- **wallclk:** Wall clock timestamp (ISO format).\n",
    "- **cl:** In-game clock in MM:SS format.\n",
    "- **de:** Description of the event.\n",
    "- **locX, locY:** X and Y coordinates on the court.\n",
    "- **opt1, opt2, opt3, opt4:** Additional optional numerical data.\n",
    "- **mtype, etype:** Codes representing event types.\n",
    "- **opid:** Optional event identifier (note many missing values).\n",
    "- **tid:** Team identifier.\n",
    "- **pid:** Player identifier.\n",
    "- **hs, vs:** Home and visitor scores.\n",
    "- **epid:** Event period identifier.\n",
    "- **oftid:** Offensive team identifier.\n",
    "- **ord:** Order of the event in the game.\n",
    "- **pts:** Points scored in the event.\n",
    "- **PERIOD:** Game period/quarter.\n",
    "- **GAME_ID:** Unique game identifier.\n",
    "\n",
    "This detailed description helps us plan the cleaning and feature engineering steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing_values_section",
   "metadata": {},
   "source": [
    "## 4. Missing Values & Data Types <a id=\"missing-values\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e75df7",
   "metadata": {},
   "source": [
    "\n",
    "We now inspect the dataset for missing values and review the current data types. This helps us identify which columns need conversion or imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de75da58",
   "metadata": {},
   "source": [
    "### 4.1 Check for Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f93d9e",
   "metadata": {},
   "source": [
    "\n",
    "In this step, we inspect the dataset for any missing values. This helps us identify which columns may need imputation or special handling during the cleaning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_missing_values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_counts = df_tracking.isnull().sum()\n",
    "print('Missing values in each column:')\n",
    "print(missing_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8133f83",
   "metadata": {},
   "source": [
    "#### Missing Values Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c1655f",
   "metadata": {},
   "source": [
    "#### Observations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bd91f",
   "metadata": {},
   "source": [
    "- **Complete Columns:**  \n",
    "  Most columns (e.g., `evt`, `wallclk`, `cl`, `de`, `locX`, `locY`, `tid`, `pid`, `hs`, `vs`, `PERIOD`, `GAME_ID`, etc.) have **0 missing values**. This indicates that these fields are fully populated and likely crucial for our analysis.\n",
    "  \n",
    "- **Columns with Missing Values:**  \n",
    "  - **opid:** There are **267,514 missing values**. This column is labeled as an optional event identifier, and the high number of missing entries might be inherent to the data source.\n",
    "  - **epid:** There are **211,048 missing values**. This column represents the event period identifier and also has many missing entries, which may indicate that this field is not consistently recorded or is optional.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26c01e",
   "metadata": {},
   "source": [
    "#### Implications for Analysis:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab7b6b",
   "metadata": {},
   "source": [
    "- Since the majority of the columns have no missing values, we can focus our cleaning efforts on understanding and handling the missing data in `opid` and `epid`.  \n",
    "- Depending on the relevance of these columns to our modeling objectives, we might choose to impute missing values, drop these columns, or simply flag them as optional data that may not affect our core analysis.\n",
    "- Overall, the quality of the tracking data is strong, with only a couple of optional fields showing missing values.\n",
    "\n",
    "This analysis of missing values helps us to identify where additional cleaning or special handling may be necessary before proceeding with further feature engineering and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ecc56",
   "metadata": {},
   "source": [
    "### 4.2 Display Current Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9bb350",
   "metadata": {},
   "source": [
    "Before converting any columns, we display the current data types of our DataFrame. This gives us insight into the structure of the data and informs us which columns need conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the current data types\n",
    "print('\\nData types:')\n",
    "print(df_tracking.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf25ffd",
   "metadata": {},
   "source": [
    "#### Data Types Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482825cf",
   "metadata": {},
   "source": [
    "Below is the output of the data types present in our dataset:\n",
    "\n",
    "```\n",
    "evt             int64\n",
    "wallclk        object\n",
    "cl             object\n",
    "de             object\n",
    "locX            int64\n",
    "locY            int64\n",
    "opt1            int64\n",
    "opt2            int64\n",
    "opt3            int64\n",
    "opt4            int64\n",
    "mtype           int64\n",
    "etype           int64\n",
    "opid          float64\n",
    "tid             int64\n",
    "pid             int64\n",
    "hs              int64\n",
    "vs              int64\n",
    "epid          float64\n",
    "oftid           int64\n",
    "ord             int64\n",
    "pts             int64\n",
    "PERIOD          int64\n",
    "GAME_ID         int64\n",
    "cl_seconds      int64\n",
    "time_diff     float64\n",
    "dx            float64\n",
    "dy            float64\n",
    "distance      float64\n",
    "velocity      float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c701f14",
   "metadata": {},
   "source": [
    "#### **Observations:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070de3b9",
   "metadata": {},
   "source": [
    "- **Integer Columns (`int64`)**:  \n",
    "  Many fields, such as `evt`, `locX`, `locY`, `tid`, `pid`, `PERIOD`, `GAME_ID`, and `pts`, are stored as integers, which is appropriate for categorical and numerical data.  \n",
    "\n",
    "- **Floating-Point Columns (`float64`)**:  \n",
    "  Fields like `opid`, `epid`, `time_diff`, `dx`, `dy`, `distance`, and `velocity` are in floating-point format, which makes sense since these involve either missing values or continuous numerical calculations.\n",
    "\n",
    "- **Object Columns (`object`)**:  \n",
    "  - `wallclk`, `cl`, and `de` are stored as **object (string) types**.  \n",
    "  - `wallclk` (wall clock timestamp) might be better converted into **datetime format** for easier time-based calculations.  \n",
    "  - `cl` (in-game clock) may need **conversion into seconds** for easier numerical operations.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c8f93e",
   "metadata": {},
   "source": [
    "#### **Next Steps:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e60f8",
   "metadata": {},
   "source": [
    "- Convert `wallclk` to `datetime64` format.\n",
    "- Transform `cl` (clock) into a numerical format (`cl_seconds`).\n",
    "- Ensure `de` (event description) remains an object since it contains textual data.\n",
    "- Check if `opid` and `epid` should be imputed or left as is.\n",
    "\n",
    "By ensuring that all data types are correctly formatted, we can perform **efficient computations, avoid type-related errors, and prepare the data for feature engineering and modeling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ea234",
   "metadata": {},
   "source": [
    "### 4.3 Convert Specific Columns to Numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768761d3",
   "metadata": {},
   "source": [
    "\n",
    "Some columns, such as spatial coordinates (`locX`, `locY`) and points (`pts`), should be numeric. We use `pd.to_numeric()` with `errors='coerce'` to ensure any non-numeric values are safely converted to `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d06a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specific columns to numeric if needed\n",
    "numeric_columns = ['locX', 'locY', 'pts']\n",
    "for col in numeric_columns:\n",
    "    df_tracking[col] = pd.to_numeric(df_tracking[col], errors='coerce')\n",
    "\n",
    "print('\\nData types after conversion:')\n",
    "print(df_tracking.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "post_conversion_analysis",
   "metadata": {},
   "source": [
    "#### Analysis of Data Type Conversion and Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c67d5",
   "metadata": {},
   "source": [
    "\n",
    "After loading the dataset, we inspected the missing values and data types. Most columns are complete; however, we observed that the columns `opid` and `epid` have many missing values, which appears to be inherent in the data source (they are optional event identifiers). \n",
    "\n",
    "We then verified that critical numerical fields such as `locX`, `locY`, and `pts` are indeed numeric. This is crucial for any arithmetic operations and feature calculations that we will perform in the next section.\n",
    "\n",
    "Additionally, we created a new column `cl_seconds` by converting the in-game clock (`cl`), which is in `MM:SS` format, into total seconds. This conversion will allow us to compute time differences between consecutive events. \n",
    "\n",
    "The data types after conversion now include additional fields from our subsequent processing (e.g., `cl_seconds`, `time_diff`, `dx`, `dy`, `distance`, and `velocity`). This sets a good foundation for our feature engineering steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5_summary",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering <a id=\"feature-engineering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dcbd5f",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we derive new features from the raw tracking data to capture the spatial and temporal dynamics of NBA player movement. These features are critical for our later modeling tasks (e.g., predicting player trajectories). The main steps include:\n",
    "\n",
    "1. Sorting the data by player identifier and time.\n",
    "2. Converting the in-game clock (in MM:SS format) to total seconds.\n",
    "3. Computing the time difference between consecutive events for each player.\n",
    "4. Calculating spatial differences (dx and dy) between consecutive positions.\n",
    "5. Computing the Euclidean distance traveled between events.\n",
    "6. Calculating velocity as distance divided by the time difference.\n",
    "\n",
    "Let's implement these steps one by one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_engineering_clock",
   "metadata": {},
   "source": [
    "### 5.1 Convert In-Game Clock to Seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46998b65",
   "metadata": {},
   "source": [
    "The column `cl` contains the in-game clock in `MM:SS` format. For numerical operations, we need to convert these values to total seconds. We will create a new column called `cl_seconds` to store this conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert_time",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to convert \"MM:SS\" to total seconds\n",
    "def time_to_seconds(time_str):\n",
    "    try:\n",
    "        parts = time_str.split(':')\n",
    "        minutes = int(parts[0])\n",
    "        # Use float conversion for the seconds part to handle decimals\n",
    "        seconds = float(parts[1])\n",
    "        return minutes * 60 + seconds\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Apply the conversion function to the 'cl' column and create a new column 'cl_seconds'\n",
    "df_tracking['cl_seconds'] = df_tracking['cl'].apply(time_to_seconds)\n",
    "\n",
    "# Display a sample to verify the conversion\n",
    "display(df_tracking[['cl', 'cl_seconds']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8a374",
   "metadata": {},
   "source": [
    "#### Investigating Event Types When the In-Game Clock is Zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24aa64a",
   "metadata": {},
   "source": [
    "In this section, we focus on rows where the in-game clock (`cl_seconds`) is 0. We want to inspect these events, analyze their descriptions, and understand what kind of events typically occur at this time (for example, \"End Period\" or \"Rebound\" events). We will split our analysis into several steps:\n",
    "1. Filter and display a sample of the zero clock events.\n",
    "2. Analyze the frequency of event descriptions.\n",
    "3. Search for specific keywords within the event descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f7314",
   "metadata": {},
   "source": [
    "**Our Goals in this Section:**\n",
    "\n",
    "- **Identify Event Types:**  \n",
    "  Analyze the `de` (event description) column to see which events are most common when `cl_seconds` is 0.\n",
    "\n",
    "- **Frequency Analysis:**  \n",
    "  Calculate the frequency of different event types (or key substrings) when the in-game clock is zero. This will help us understand whether a large number of events occur at the end of periods or if there are any anomalies.\n",
    "\n",
    "- **Implications for Feature Engineering:**  \n",
    "  Knowing the context behind these low clock values may inform how we treat them in further analysis (for example, whether to exclude some events or adjust our feature engineering steps).\n",
    "\n",
    "Let's proceed by exploring the event descriptions for records with `cl_seconds` equal to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b87541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows where cl_seconds is 0\n",
    "zero_clock_events = df_tracking[df_tracking['cl_seconds'] == 0]\n",
    "\n",
    "# Display a sample of these events to see what the event descriptions look like\n",
    "display(zero_clock_events[['cl', 'cl_seconds', 'de', 'evt']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1229937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the frequency of event descriptions in these zero clock events\n",
    "event_counts = zero_clock_events['de'].value_counts()\n",
    "\n",
    "print(\"Frequency of event descriptions when cl_seconds == 0:\")\n",
    "print(event_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0660b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, if we want to check for keywords (e.g., 'End Period', 'Rebound')\n",
    "keywords = ['End Period', 'Rebound', 'Shot', 'Turnover', 'Foul', 'Replay']\n",
    "for keyword in keywords:\n",
    "    keyword_count = zero_clock_events['de'].str.contains(keyword, case=False, na=False).sum()\n",
    "    print(f\"Number of events containing '{keyword}': {keyword_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef33f1",
   "metadata": {},
   "source": [
    "#### Summary of Investigating Zero Clock Events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f08f3",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we filtered the dataset to focus on events where the in-game clock (`cl_seconds`) is 0. Our analysis revealed the following:\n",
    "\n",
    "- **Frequency Analysis:**  \n",
    "  - \"End Period\" events are dominant, with 2,611 occurrences.\n",
    "  - There are 390 events containing the keyword \"Rebound.\" and 494 events with the keyword \"Shot.\" and 243 events with the keyword \"Turnover.\"\n",
    "  - Other keywords such as \"Turnover\"  and \"Replay\" appear with lower frequencies.\n",
    "  \n",
    "- **Implications:**  \n",
    "  - The prevalence of \"End Period\" events confirms that many events naturally occur at the end of a period.\n",
    "  - The frequency of other events (like rebounds and shots) at 0 seconds provides context on how some actions are recorded right at the period boundaries.\n",
    "  - This insight is useful for our feature engineering because it suggests that events with `cl_seconds` of 0 may need to be flagged or handled differently during modeling.\n",
    "\n",
    "With these observations in hand, we are now ready to move on to the next step in our feature engineering process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_engineering_derived",
   "metadata": {},
   "source": [
    "### 5.2 Sorting the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391eece",
   "metadata": {},
   "source": [
    "\n",
    "To accurately compute differences between consecutive events, we need to ensure that the data for each player is sorted in chronological order. We'll sort the DataFrame by the player identifier (`pid`) and the converted in-game clock (`cl_seconds`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by player identifier and in-game time (cl_seconds)\n",
    "df_tracking.sort_values(by=['pid', 'cl_seconds'], inplace=True)\n",
    "\n",
    "# Verify sorting by displaying a sample of rows for a specific player\n",
    "sample_pid = df_tracking['pid'].iloc[0]\n",
    "display(df_tracking[df_tracking['pid'] == sample_pid].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb1c20",
   "metadata": {},
   "source": [
    "**Observations from the Sorting Step:**\n",
    "\n",
    "- The sample output shows rows for a specific player (`pid` value 0) sorted by the `cl_seconds` column.\n",
    "- In our sample, all `cl_seconds` values appear as `0.0`. This indicates one of two possibilities:\n",
    "  - **Many events occur at \"00:00\":**  \n",
    "    It is plausible that many events for this player occur right at the end of a period (e.g., \"End Period\" events), which might be recorded as \"00:00\". However, if all values are 0, this is unlikely for the entire dataset.\n",
    "  - **Time Conversion Issue:**  \n",
    "    There might be an issue with our `time_to_seconds` function. For example, if the clock values include decimals (e.g., \"00:00.4\"), our current function might be truncating or failing to properly capture the fractional part. This would result in `cl_seconds` being 0 for such values.\n",
    "\n",
    "- The sorting logic itself is working correctly, as it orders the data by `pid` and `cl_seconds`. This is crucial because accurate sorting is the foundation for computing time differences, spatial differences, and ultimately, velocity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34483086",
   "metadata": {},
   "source": [
    "**Next Steps:**\n",
    "\n",
    "- Investigate the conversion of the `cl` column to `cl_seconds` to ensure it correctly converts values like `\"00:00.4\"` to `0.4` seconds rather than `0`.\n",
    "- Once the time values are correctly converted, the computed `time_diff` should reflect the actual elapsed time between events, and the derived velocity values will be more meaningful.\n",
    "- Continue with the subsequent feature engineering steps (time differences, spatial differences, distance, and velocity) after ensuring the clock conversion is accurate.\n",
    "\n",
    "This summary confirms that while our sorting logic works as expected, we need to double-check the time conversion to ensure that our derived features accurately capture the temporal dynamics of the game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0fdc8",
   "metadata": {},
   "source": [
    "### 5.3 Calculating Time Differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a6df3",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have ensured our data is sorted by the player identifier (`pid`) and the converted in-game clock (`cl_seconds`), our next step is to calculate the time difference between consecutive events for each player.\n",
    "\n",
    "**Why This Step is Important:**\n",
    "- The time difference, stored in a new column `time_diff`, represents the elapsed time (in seconds) between successive events for a player.\n",
    "- This feature is critical for calculating other dynamic metrics such as velocity.\n",
    "- Accurate time differences help us understand the pace of play and the temporal dynamics of player movement.\n",
    "\n",
    "We use the `.groupby()` method to group events by `pid` and then apply `.diff()` on the `cl_seconds` column to compute the difference between consecutive time stamps. If there is no previous event (i.e., the first event for a player), we fill the missing value with `0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time difference (in seconds) between consecutive events for each player\n",
    "df_tracking['time_diff'] = df_tracking.groupby('pid')['cl_seconds'].diff().fillna(0)\n",
    "\n",
    "# Display a sample of the new 'time_diff' column alongside 'pid' and 'cl_seconds'\n",
    "display(df_tracking[['pid', 'cl', 'cl_seconds', 'time_diff']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9048d",
   "metadata": {},
   "source": [
    "#### Additional Comparison of Time Differences\n",
    "\n",
    "To better understand the time dynamics, we can compare the `time_diff` values across multiple players. This will help us identify if the 0-second differences are consistent across players or if some players have events with non-zero intervals. \n",
    "\n",
    "Below, we display the first 10 events for a few different player IDs to see how the time differences vary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of unique player IDs from the dataset (for example, the first 5 unique players)\n",
    "unique_players = df_tracking['pid'].unique()[:5]\n",
    "print(\"Sample of unique player IDs:\", unique_players)\n",
    "\n",
    "# For each sampled player, display the first 10 events and their time differences\n",
    "for player in unique_players:\n",
    "    print(f\"\\nEvents for player {player}:\")\n",
    "    display(df_tracking[df_tracking['pid'] == player][['cl', 'cl_seconds', 'time_diff']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff349e",
   "metadata": {},
   "source": [
    "#### Conclusion: Data Sorting and Time Differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6470c7",
   "metadata": {},
   "source": [
    "\n",
    "From our analysis of the sorted data and computed time differences, we observed the following:\n",
    "\n",
    "- **Player 0:**  \n",
    "  All events for player 0 show a `cl_seconds` value of 0 and, consequently, a `time_diff` of 0. This suggests that for player 0, the events we sampled (such as \"End Period\" events) occur at the boundary where the in-game clock reads \"00:00\".  \n",
    "- **Other Players (e.g., 1320, 1371, 1497, 1658):**  \n",
    "  - Players such as 1320, 1371, and others show non-zero values for `cl_seconds` and non-zero `time_diff` values, which indicates that the time conversion is working properly for those events.\n",
    "  - For instance, player 1320 has events with clock times like \"00:49.9\", \"02:16\", \"06:47\", and \"08:44\" (converted to seconds as 49.9, 136.0, 407.0, and 524.0, respectively), with corresponding time differences that reflect the elapsed time between events.\n",
    "  \n",
    "**Implications:**\n",
    "\n",
    "- The sorting operation appears to be working correctly, as events for each player are ordered by their converted in-game clock (`cl_seconds`).\n",
    "- The computed time differences (`time_diff`) vary as expected among players, which will be crucial for calculating derived features such as velocity in subsequent steps.\n",
    "- The fact that some players (like player 0) consistently have `cl_seconds` equal to 0 is likely due to the nature of those events (e.g., \"End Period\"). This confirms that we need to consider the context when interpreting the time differences and the derived features.\n",
    "\n",
    "With these observations, we conclude that our sorting and time difference computations are functioning as intended. We are now ready to move on to the next phase of feature engineering—specifically, computing spatial differences and then using these differences to calculate distance and velocity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5929f3da",
   "metadata": {},
   "source": [
    "### 5.4 Computing Spatial Differences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b833a352",
   "metadata": {},
   "source": [
    "In this step, we calculate how much a player's position changes between consecutive events. We do this by computing:\n",
    "\n",
    "- **dx:** The difference in the X coordinate (`locX`) between consecutive events for each player.\n",
    "- **dy:** The difference in the Y coordinate (`locY`) between consecutive events for each player.\n",
    "\n",
    "**Why is this important?**\n",
    "- These differences quantify the player's movement in each direction.\n",
    "- They are essential for calculating the Euclidean distance traveled between events.\n",
    "- Accurate spatial differences are a key input for computing dynamic features like velocity.\n",
    "\n",
    "We achieve this by grouping the data by the player identifier (`pid`) and applying the `.diff()` method to the `locX` and `locY` columns. Any missing differences (e.g., for the first event of each player) are filled with 0.\n",
    "\n",
    "Let's implement these steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference in the X coordinate (dx) for each player\n",
    "df_tracking['dx'] = df_tracking.groupby('pid')['locX'].diff().fillna(0)\n",
    "\n",
    "# Compute the difference in the Y coordinate (dy) for each player\n",
    "df_tracking['dy'] = df_tracking.groupby('pid')['locY'].diff().fillna(0)\n",
    "\n",
    "# Display a sample of the computed spatial differences\n",
    "display(df_tracking[['pid', 'locX', 'locY', 'dx', 'dy']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc16aa",
   "metadata": {},
   "source": [
    "#### Examining Spatial Differences in Later Events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ebea7",
   "metadata": {},
   "source": [
    "\n",
    "The first event for each player naturally has `dx` and `dy` equal to 0 because there's no previous event for comparison. To confirm that our spatial difference calculations are working correctly, we need to inspect events later in a player’s sequence where we expect movement to occur.\n",
    "\n",
    "We will:\n",
    "- Filter for events where the `time_diff` is greater than 0 (indicating that this is not the first event).\n",
    "- Display a sample for a few players to check that `dx` and `dy` have nonzero values when appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for events where the time difference is greater than 0\n",
    "nonzero_time_events = df_tracking[df_tracking['time_diff'] > 0]\n",
    "\n",
    "# Display a sample of these events for a few different players\n",
    "sample_players = nonzero_time_events['pid'].unique()[:3]  # take 3 unique players\n",
    "for player in sample_players:\n",
    "    print(f\"\\nEvents for player {player} with nonzero time differences:\")\n",
    "    display(nonzero_time_events[nonzero_time_events['pid'] == player][['cl', 'cl_seconds', 'time_diff', 'locX', 'locY', 'dx', 'dy']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6246db7",
   "metadata": {},
   "source": [
    "#### Conclusion: Spatial Differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88eedf",
   "metadata": {},
   "source": [
    "\n",
    "After filtering for events with nonzero time differences, we examined the spatial differences (`dx` and `dy`) between consecutive events for several players. Our observations are as follows:\n",
    "\n",
    "- **Player 0:**  \n",
    "  We see nonzero values in many of the events, indicating that this player’s position does change over time. For example, in some events, the differences (`dx` and `dy`) are substantial (e.g., -199 and 454), reflecting noticeable movement.\n",
    "  \n",
    "- **Players 1320 and 1371:**  \n",
    "  The sample events for these players show that their `dx` and `dy` values are consistently 0. This could indicate that either these events represent moments when these players are stationary (for instance, during certain types of events such as \"End Period\" or other non-movement-related events) or that the data for those specific events does not capture spatial change.\n",
    "\n",
    "**Implications:**\n",
    "\n",
    "- The nonzero spatial differences for player 0 confirm that our method for computing `dx` and `dy` is working as expected for events where movement occurs.\n",
    "- For players with zero differences, it's important to consider the context of the events. If these events are expected to have little or no movement (for example, if they are administrative or boundary events), then zero values are acceptable.\n",
    "- In further analysis and modeling, we may want to flag events with zero movement separately or investigate the context behind these records to decide how they should influence the modeling process.\n",
    "\n",
    "With the spatial differences computed and validated, we now have the necessary components to proceed with the next step: calculating the Euclidean distance and then velocity. This will further enrich our feature set for modeling player movement dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b679217",
   "metadata": {},
   "source": [
    "### 5.5 Calculating Euclidean Distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223667dd",
   "metadata": {},
   "source": [
    "Using the spatial differences (`dx` and `dy`) computed in Section 5.4, we now calculate the Euclidean distance traveled between consecutive positions. This distance represents the straight-line distance that a player (or the ball) moved from one event to the next.\n",
    "\n",
    "The formula used is:\n",
    "\n",
    "$$\n",
    "\\text{distance} = \\sqrt{dx^2 + dy^2}\n",
    "$$\n",
    "\n",
    "**Why this is important:**\n",
    "- **Quantifying Movement:** The distance provides a quantitative measure of how far a player moved between events.\n",
    "- **Foundation for Velocity Calculation:** This distance, combined with the time difference (`time_diff`), is used to compute the player's velocity.\n",
    "- **Data Quality Check:** Nonzero distances in events with a nonzero `time_diff` indicate that the spatial tracking data is capturing movement accurately.\n",
    "\n",
    "Let's implement the calculation of the Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dffb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Euclidean distance between consecutive positions using the formula: distance = sqrt(dx^2 + dy^2)\n",
    "df_tracking['distance'] = np.sqrt(df_tracking['dx']**2 + df_tracking['dy']**2)\n",
    "\n",
    "# Display a sample of the computed distance alongside the spatial differences for verification\n",
    "display(df_tracking[['pid', 'dx', 'dy', 'distance']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3de6f2",
   "metadata": {},
   "source": [
    "Now, we have computed the Euclidean distance traveled between consecutive events for each player. This distance metric is crucial for understanding player movement dynamics and will serve as a key input for calculating velocity in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde628ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter events with a nonzero distance to show cases with movement\n",
    "movement_events = df_tracking[df_tracking['distance'] > 0]\n",
    "\n",
    "# Display a sample of these events to inspect the movement details\n",
    "display(movement_events[['pid', 'cl', 'cl_seconds', 'dx', 'dy', 'distance']].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc267ea7",
   "metadata": {},
   "source": [
    "#### Conclusion: Euclidean Distance and Movement Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cc7396",
   "metadata": {},
   "source": [
    "From our analysis of spatial differences, we computed the Euclidean distance using the formula:\n",
    "\n",
    "$$\n",
    "\\text{distance} = \\sqrt{dx^2 + dy^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb1f42",
   "metadata": {},
   "source": [
    "\n",
    "**Key Observations:**\n",
    "\n",
    "- For many events, especially the first event for each player, the computed `distance` is 0, as expected, because there is no prior position to compare.\n",
    "- In contrast, for later events we see significant nonzero distance values. For example:\n",
    "  - Player 460 shows a distance of approximately 202.63 units when transitioning from one event to the next.\n",
    "  - Other players (e.g., player 1317, 2049, etc.) exhibit distances in the range of 86.68 to 621.49 units, indicating measurable movement.\n",
    "- These nonzero distances confirm that our spatial difference calculations (i.e., `dx` and `dy`) are capturing meaningful movement between events.\n",
    "\n",
    "**Implications:**\n",
    "\n",
    "- The Euclidean distance feature is a reliable measure of how far players (or the ball) move between successive events.\n",
    "- These distance values will be a crucial input for calculating velocity in the next section.\n",
    "- Additionally, by examining these distances, we can later explore patterns such as bursts of movement, changes in pace, or differences across event types.\n",
    "\n",
    "With the spatial differences and distances computed and validated, we now have a robust feature set capturing the physical movement on the court. We are ready to move on to the next step: calculating velocity (Section 5.6), which will combine these distance values with the computed time differences to quantify the rate of movement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220431f7",
   "metadata": {},
   "source": [
    "### 5.6 Calculating Velocity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f79e4d4",
   "metadata": {},
   "source": [
    "Velocity is computed as the distance traveled divided by the time difference between consecutive events:\n",
    "\n",
    "$$\n",
    "\\text{velocity} = \\frac{\\text{distance}}{\\text{time\\_diff}}\n",
    "$$\n",
    "\n",
    "This formula assumes both distance and time\\_diff are correctly computed (with non-zero values) before calculating velocity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab3fc50",
   "metadata": {},
   "source": [
    "\n",
    "**Important Considerations:**\n",
    "\n",
    "- **Zero Time Difference:**  \n",
    "  When `time_diff` is 0 (e.g., for the first event of each player or events recorded at the exact same timestamp), division by zero must be avoided. In these cases, we set the velocity to 0.\n",
    "  \n",
    "- **Physical Interpretation:**  \n",
    "  The calculated velocity represents the rate of movement between events. Nonzero values indicate measurable movement, while 0 indicates no movement or that it is the first event in a sequence.\n",
    "\n",
    "We use a lambda function with an if-else condition to safely compute the velocity for each row. This ensures that if `time_diff` is zero, the velocity is explicitly set to 0.\n",
    "\n",
    "Let's implement this calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3669727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute velocity as the ratio of distance to time_diff,\n",
    "# with a safeguard to handle cases where time_diff is zero.\n",
    "df_tracking['velocity'] = df_tracking.apply(\n",
    "    lambda row: row['distance'] / row['time_diff'] if row['time_diff'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display a sample of the computed velocity alongside related features for verification\n",
    "display(df_tracking[['pid', 'cl', 'cl_seconds', 'time_diff', 'distance', 'velocity']].head(10))\n",
    "\n",
    "print(\"Velocity computation completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8173078",
   "metadata": {},
   "source": [
    "#### Examining Velocity for Events with Nonzero Time Differences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171798f",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have computed the velocity, we want to focus on events where the time difference (`time_diff`) is greater than 0. This will allow us to inspect cases where there is measurable movement and verify that the computed velocity is meaningful. The following cell filters these events and displays a sample for multiple players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef09f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for events with a nonzero time difference\n",
    "nonzero_velocity_events = df_tracking[df_tracking['time_diff'] > 0]\n",
    "\n",
    "# Display a sample of these events to verify the computed velocity alongside other features\n",
    "display(nonzero_velocity_events[['pid', 'cl', 'cl_seconds', 'time_diff', 'distance', 'velocity']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c33c6",
   "metadata": {},
   "source": [
    "#### Conclusion: Velocity Calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f41926",
   "metadata": {},
   "source": [
    "\n",
    "The velocity for each event has been computed as the ratio of the Euclidean distance traveled to the time difference between consecutive events:\n",
    "\n",
    "$$\n",
    "\\text{velocity} = \\frac{\\text{distance}}{\\text{time\\_diff}}\n",
    "$$\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "- **Nonzero Time Differences:**  \n",
    "  For events where the time difference is greater than 0, we observe nonzero velocity values. For example, in the sample for player 0, we see velocities such as 4956.98, 3144.30, 6984.84, etc. These values represent the rate of movement between consecutive events.\n",
    "\n",
    "- **Magnitude of Velocities:**  \n",
    "  The velocities appear to be very high. This may be due to the spatial coordinates' scale or the very short time intervals (fractions of a second) between events. Such high values can occur when even small changes in position are divided by a very small time difference.\n",
    "\n",
    "- **Zero Velocities:**  \n",
    "  For events where `time_diff` is 0 (typically the first event for each player or events recorded at the exact same timestamp), the velocity is correctly set to 0, as per our handling in the lambda function.\n",
    "\n",
    "**Implications:**\n",
    "\n",
    "- The computed velocity feature successfully captures the movement rate between consecutive events.  \n",
    "- The high velocity values should be interpreted in the context of our data's scale and the very short time intervals. We may consider further normalization or clipping of these values in later steps, depending on the requirements of our modeling process.\n",
    "- These velocity values, together with the other engineered features (time difference, spatial differences, and Euclidean distance), provide a robust foundation for understanding player movement dynamics and will serve as important inputs for our subsequent modeling tasks.\n",
    "\n",
    "With the velocity calculation validated, we now have a comprehensive set of features to represent both the spatial and temporal dynamics of the game. We are ready to proceed to the next steps in our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34bf5c",
   "metadata": {},
   "source": [
    "### 5.7 Summary of Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88f220",
   "metadata": {},
   "source": [
    "In this chapter, we systematically derived new features from the raw tracking data to capture the spatial and temporal dynamics of NBA player movement. Here's an overview of what we accomplished:\n",
    "\n",
    "1. **Convert In-Game Clock to Seconds (5.1):**\n",
    "   - We converted the `cl` column (in `MM:SS` format) to total seconds, storing the result in a new column called `cl_seconds`.  \n",
    "   - This conversion allows us to perform numerical computations on time values and is essential for computing time differences.\n",
    "\n",
    "2. **Sorting the Data (5.2):**\n",
    "   - The DataFrame was sorted by the player identifier (`pid`) and the converted in-game clock (`cl_seconds`), ensuring that events for each player are in chronological order.\n",
    "   - Proper ordering is critical for accurately computing differences between consecutive events.\n",
    "\n",
    "3. **Calculating Time Differences (5.3):**\n",
    "   - We computed the elapsed time (`time_diff`) between consecutive events for each player using the `cl_seconds` column.\n",
    "   - This feature is a key input for calculating velocity and understanding the temporal dynamics of the game.\n",
    "\n",
    "4. **Computing Spatial Differences (5.4):**\n",
    "   - We calculated the differences in the X and Y coordinates (`dx` and `dy`) between consecutive events for each player.\n",
    "   - These differences quantify the movement along each axis and set the stage for computing the physical distance traveled.\n",
    "\n",
    "5. **Calculating Euclidean Distance (5.5):**\n",
    "   - Using the computed spatial differences, we calculated the Euclidean distance with the formula:  \n",
    "     $$ \\text{distance} = \\sqrt{dx^2 + dy^2} $$\n",
    "   - This measure represents the straight-line distance a player moved between consecutive events.\n",
    "\n",
    "6. **Calculating Velocity (5.6):**\n",
    "   - Finally, we derived the velocity feature by dividing the Euclidean distance by the time difference (`distance / time_diff`), with appropriate handling for cases where `time_diff` is 0.\n",
    "   - The velocity provides a measure of the rate of movement, which is essential for capturing dynamic aspects of gameplay.\n",
    "\n",
    "**Overall Implications:**\n",
    "\n",
    "- The engineered features (time differences, spatial differences, distance, and velocity) collectively provide a robust foundation for modeling player movement dynamics.\n",
    "- These features will be crucial inputs for subsequent modeling tasks such as predicting trajectories and detecting key events during the game.\n",
    "- While some players exhibit 0 values (typically at the start of their sequences or during boundary events), other players show measurable changes, validating the effectiveness of our feature engineering pipeline.\n",
    "\n",
    "With these features in place, our dataset is now well-prepared for further analysis and modeling. Next, we can focus on integrating these features with additional data or proceeding to advanced exploratory data analysis and model development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda_section",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis (EDA) <a id=\"eda\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527427d",
   "metadata": {},
   "source": [
    "In this chapter, we perform a thorough exploratory analysis of our engineered features and the original tracking data. Our objectives are to understand the distribution and relationships of our variables, identify potential outliers, and gain insights that will inform our subsequent modeling steps. The chapter is organized as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0dc41b",
   "metadata": {},
   "source": [
    "\n",
    "1. **Introduction to EDA**\n",
    "   - Overview of the goals of EDA\n",
    "   - Summary of the features under analysis (e.g., `cl_seconds`, `time_diff`, `dx`, `dy`, `distance`, `velocity`)\n",
    "\n",
    "2. **Summary Statistics**\n",
    "   - Descriptive statistics for both original and engineered features\n",
    "   - Insights from the summary (e.g., mean, median, standard deviation, etc.)\n",
    "\n",
    "3. **Distribution Analysis**\n",
    "   - Histograms and Kernel Density Estimates (KDE) for key numerical features\n",
    "   - Box plots to identify outliers\n",
    "   - Discussion of the spread and central tendency of features\n",
    "\n",
    "4. **Spatial Trajectory Visualization**\n",
    "   - Scatter plots of spatial coordinates (e.g., `locX` vs. `locY`)\n",
    "   - Visualizing trajectories for selected players, possibly with color-coding by time or event type\n",
    "\n",
    "5. **Correlation Analysis**\n",
    "   - Correlation matrix of engineered features\n",
    "   - Heatmaps to identify strong relationships among features\n",
    "   - Discussion on how these correlations might affect model performance\n",
    "\n",
    "6. **Event-Specific Analysis**\n",
    "   - Comparison of feature distributions across different event types (e.g., \"End Period\", \"Rebound\", etc.)\n",
    "   - Analysis of how event context influences movement dynamics\n",
    "\n",
    "7. **Summary of EDA Findings**\n",
    "   - Key insights and observations from the exploratory analysis\n",
    "   - Implications for feature selection and model development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10559ef",
   "metadata": {},
   "source": [
    "### 6.1 Summary Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f1f77",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we will compute and review descriptive statistics for our dataset. Our focus will be on both the original tracking features (e.g., `locX`, `locY`, `cl_seconds`) and the engineered features (e.g., `time_diff`, `dx`, `dy`, `distance`, `velocity`).\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "- **Descriptive Overview:**  \n",
    "  Provide an overview of key statistics (mean, median, standard deviation, min, max, quartiles) for each numerical feature. This helps in understanding the central tendency and dispersion of the data.\n",
    "\n",
    "- **Identify Outliers:**  \n",
    "  Look for unusual values or extreme variations in the distributions that may need further investigation or special handling during modeling.\n",
    "\n",
    "- **Compare Features:**  \n",
    "  Compare the distributions of the engineered features to see if they behave as expected (e.g., nonzero time differences, meaningful spatial differences, reasonable distances and velocity values).\n",
    "\n",
    "The results from this analysis will inform any necessary adjustments in preprocessing and feature engineering before moving on to more advanced EDA and modeling.\n",
    "\n",
    "Let's now proceed to calculate these summary statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics for the original features and engineered features.\n",
    "# Here we consider columns: cl_seconds, time_diff, locX, locY, dx, dy, distance, velocity\n",
    "\n",
    "summary_stats = df_tracking[['cl_seconds', 'time_diff', 'locX', 'locY', 'dx', 'dy', 'distance', 'velocity']].describe()\n",
    "print(\"Summary Statistics for Key Features:\")\n",
    "display(summary_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452c2cb",
   "metadata": {},
   "source": [
    "#### Summary Statistics – Review and Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6eb893",
   "metadata": {},
   "source": [
    "\n",
    "The descriptive statistics for our key features provide several important insights into the dynamics of the tracking data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf095396",
   "metadata": {},
   "source": [
    "\n",
    "- **In-Game Clock (`cl_seconds`):**  \n",
    "  - **Range:** 0 to 720 seconds (0 to 12 minutes)  \n",
    "  - **Mean & Median:** Mean is approximately 338.24 seconds, and the median is 335.0 seconds.  \n",
    "  - **Interpretation:** These values are consistent with the expected duration of a period, indicating that our conversion from `MM:SS` to seconds is functioning as expected.\n",
    "\n",
    "- **Time Difference (`time_diff`):**  \n",
    "  - **Central Tendency:** The mean time difference is about 1.20 seconds, with a median of 0.6 seconds.  \n",
    "  - **Variation:** The standard deviation is 4.18 seconds, and although most events occur in rapid succession (with the 75th percentile at 1.0 second), there are some events with very high time gaps (up to 485 seconds), which might correspond to period transitions or pauses.\n",
    "  \n",
    "- **Spatial Coordinates (`locX` and `locY`):**  \n",
    "  - **`locX`:** Ranges from -250 to 250 with a median around 0, suggesting that the court is centered on the X-axis as expected.\n",
    "  - **`locY`:** Ranges from -80 to 887 with a median of 23, reflecting a broader distribution that captures various court positions and potential extreme values.\n",
    "  \n",
    "- **Spatial Differences (`dx` and `dy`):**  \n",
    "  - **Observations:** Both `dx` and `dy` have medians of 0, which is expected since the first event for each player (or stationary phases) will have no change in position.  \n",
    "  - **Variability:** The standard deviations (approximately 135.83 for `dx` and 174.22 for `dy`) indicate that when movement occurs, it can be substantial.\n",
    "  \n",
    "- **Euclidean Distance (`distance`):**  \n",
    "  - **Summary:** With a mean of about 171.87 units and a median of 159.13 units, the distance values indicate a wide range of movement, from small positional changes to large movements (up to nearly 976 units).\n",
    "  - **Interpretation:** This feature effectively quantifies the magnitude of player movement between events.\n",
    "  \n",
    "- **Velocity:**  \n",
    "  - **Calculation:** Velocity is computed as `distance / time_diff`.  \n",
    "  - **Distribution:** The mean velocity is approximately 112.49 units per second; however, the median is 0. This suggests a skewed distribution, where many events (e.g., the first events or stationary periods) yield a velocity of 0, while a subset of events exhibits very high velocities.  \n",
    "  - **Implication:** The high standard deviation (333.30) indicates significant variability, highlighting that some moments in the game involve rapid movements.\n",
    "\n",
    "**Overall Conclusions:**\n",
    "\n",
    "- **Feature Effectiveness:**  \n",
    "  The engineered features (time difference, spatial differences, Euclidean distance, and velocity) capture both the temporal and spatial dynamics of player movement. They exhibit expected behavior (e.g., many zero values where no movement occurs, and nonzero values when movement is present).\n",
    "\n",
    "- **Data Insights:**  \n",
    "  The summary statistics indicate that while many events (especially initial events for each player) have minimal movement, there are significant bursts of movement captured by the data. This variability is critical for understanding the dynamics of gameplay and will be valuable for subsequent modeling.\n",
    "\n",
    "- **Next Steps:**  \n",
    "  With a solid understanding of our feature distributions, we are now ready to proceed with further exploratory data analysis (EDA) to visualize these patterns and eventually integrate these features into predictive models.\n",
    "\n",
    "These insights confirm that our feature engineering pipeline is robust and that our derived features are capturing meaningful aspects of the game dynamics. Next, we will delve deeper into visualizing these relationships and exploring the correlations between features in the next section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda_visualizations",
   "metadata": {},
   "source": [
    "### 6.2 Distribution Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135d5a4",
   "metadata": {},
   "source": [
    "In this section, we will explore the distributions of both the original and engineered features to gain deeper insights into their behavior. Our analysis will focus on the following aspects:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a459b8",
   "metadata": {},
   "source": [
    "1. **Histograms and Kernel Density Estimates (KDE):**  \n",
    "   - Visualize the distribution of continuous features such as `cl_seconds`, `time_diff`, `distance`, and `velocity`.  \n",
    "   - Use histograms to observe the frequency of different values and KDE plots to understand the underlying density.\n",
    "\n",
    "2. **Box Plots:**  \n",
    "   - Generate box plots for key features to identify outliers and assess the spread and symmetry of the distributions.\n",
    "   - Box plots will help us pinpoint potential anomalies or extreme values that might require further investigation.\n",
    "\n",
    "3. **Comparative Analysis:**  \n",
    "   - Compare the distributions of engineered features (e.g., `time_diff`, `distance`, `velocity`) to assess whether they behave as expected.\n",
    "   - Identify if there are any skewed distributions or unexpected patterns that could affect subsequent modeling efforts.\n",
    "\n",
    "4. **Insights and Implications:**  \n",
    "   - Summarize key findings from the visualizations, including central tendencies, dispersion, and the presence of outliers.\n",
    "   - Discuss how these insights might inform adjustments in data preprocessing, normalization, or model selection.\n",
    "\n",
    "The goal of this section is to obtain a comprehensive visual understanding of our data’s distribution, ensuring that our engineered features are well-behaved and suitable for use in modeling.\n",
    "\n",
    "Once we have a clear picture of these distributions, we will use the insights to inform any necessary transformations and to guide our feature selection for predictive modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10c501",
   "metadata": {},
   "source": [
    "#### 6.2.1 Histograms and KDE Plots for Key Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3039444",
   "metadata": {},
   "source": [
    "In this section, we will visualize the distributions of several key continuous features using histograms with Kernel Density Estimate (KDE) overlays. Specifically, we will analyze:\n",
    "\n",
    "- **cl_seconds:** The in-game clock in seconds.\n",
    "- **time_diff:** The time difference between consecutive events for each player.\n",
    "- **distance:** The Euclidean distance traveled between consecutive positions.\n",
    "- **velocity:** The computed velocity as the ratio of distance to time difference.\n",
    "\n",
    "These visualizations will help us understand the central tendencies, spread, and potential outliers in our data, which is crucial for further analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2395e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a list of key features to visualize\n",
    "features = ['cl_seconds', 'time_diff', 'distance', 'velocity']\n",
    "\n",
    "# Define a list of colors for each feature (you can customize these as needed)\n",
    "colors = ['skyblue', 'salmon', 'lightgreen', 'plum']\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n",
    "axes = axes.flatten()  # flatten the 2D array of axes for easy iteration\n",
    "\n",
    "# Loop through each feature and corresponding axis\n",
    "for ax, feature, color in zip(axes, features, colors):\n",
    "    sns.histplot(df_tracking[feature], bins=50, kde=True, color=color, ax=ax)\n",
    "    ax.set_title(f\"Distribution of {feature}\")\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Adjust the layout for better spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244b6da",
   "metadata": {},
   "source": [
    "##### Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d517e4",
   "metadata": {},
   "source": [
    "\n",
    "1. **Distribution of `cl_seconds` (top‐left):**  \n",
    "   - The histogram spans roughly from 0 up to around 650+ seconds.\n",
    "   - There is a pronounced peak near 0 (suggesting many entries close to zero), and then the frequency fluctuates but remains relatively high throughout the 100–600 second range.\n",
    "   - Toward the upper end (beyond ~600 seconds), the frequencies taper off.\n",
    "   - Overall, it’s a right‐skewed distribution with a strong concentration near zero but still substantial counts across a wide midrange of `cl_seconds`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6c0a2",
   "metadata": {},
   "source": [
    "2. **Distribution of `time_diff` (top‐right):**  \n",
    "   - The x‐axis goes from 0 to about 500, while the y‐axis extends to over 1.5×10^6 in frequency, indicating a *very* high count of near-zero values.\n",
    "   - There is a sharp drop-off after a small number of seconds, so most `time_diff` values are clustered very close to zero, with relatively few data points above even a few seconds.\n",
    "   - In other words, it is *highly* right‐skewed, dominated by very small `time_diff` values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebce4b",
   "metadata": {},
   "source": [
    "3. **Distribution of `distance` (bottom‐left):**  \n",
    "   - The range shown is from 0 to 1000.\n",
    "   - There is an initial large spike near zero—again suggesting a high volume of distances close to zero.\n",
    "   - Beyond that, the histogram shows multiple modes (several peaks around 50–200 and some around 200–300), then frequencies drop to near zero by ~500–600 onward.\n",
    "   - Overall, the data is concentrated in lower distances with some secondary clusters in the midrange.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c8616f",
   "metadata": {},
   "source": [
    "4. **Distribution of `velocity` (bottom‐right):**  \n",
    "   - The velocity axis goes from 0 to nearly 9000, but the vast majority of observations are near zero, as seen by the extreme spike in frequency at low velocities.\n",
    "   - After that initial spike, frequency declines rapidly, and only a long tail extends out to higher velocities.\n",
    "   - Similar to `time_diff`, it displays a strong right skew, with the bulk of velocities clustering very close to zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a66fc",
   "metadata": {},
   "source": [
    "These observations provide a detailed understanding of the behavior of our key features. The insights gained from this analysis will inform any necessary transformations (such as normalization or outlier handling) before integrating these features into our modeling process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d609a9",
   "metadata": {},
   "source": [
    "#### 6.2.2 Boxplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ba75f",
   "metadata": {},
   "source": [
    "In this section, we use boxplots to visualize the distribution of our key features. Boxplots are useful for:\n",
    "\n",
    "- **Identifying Outliers:**  \n",
    "  They clearly show the median, quartiles, and potential outliers in the data.\n",
    "  \n",
    "- **Understanding Spread and Central Tendency:**  \n",
    "  The box shows the interquartile range (IQR) and the whiskers indicate the range of the data, providing insights into the overall distribution.\n",
    "\n",
    "We will create boxplots for the following features:\n",
    "- `cl_seconds`\n",
    "- `time_diff`\n",
    "- `distance`\n",
    "- `velocity`\n",
    "\n",
    "By comparing these boxplots, we can assess the variability in our data and identify any extreme values that may require further investigation or transformation before modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# List of key features to visualize with boxplots\n",
    "features = ['cl_seconds', 'time_diff', 'distance', 'velocity']\n",
    "\n",
    "# Define a list of colors for each boxplot (customize as needed)\n",
    "colors = ['skyblue', 'salmon', 'lightgreen', 'plum']\n",
    "\n",
    "# Create a figure with subplots (one boxplot per feature)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "# Loop through each feature, plot its boxplot, and set appropriate titles and labels\n",
    "for ax, feature, color in zip(axes, features, colors):\n",
    "    sns.boxplot(data=df_tracking, x=feature, color=color, ax=ax)\n",
    "    ax.set_title(f\"Boxplot of {feature}\")\n",
    "    ax.set_xlabel(feature)\n",
    "\n",
    "# Adjust the layout for better spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c07dc",
   "metadata": {},
   "source": [
    "##### Analysis and Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513cd54",
   "metadata": {},
   "source": [
    "\n",
    "From the boxplots, we observe that all four key variables exhibit strong right-skewness, with many outliers on the high end. Here are the detailed observations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e235a7",
   "metadata": {},
   "source": [
    "\n",
    "1. **`cl_seconds`**  \n",
    "   - The interquartile range (IQR) spans roughly from about 200 seconds up to the 400–450 second range, with the median falling near the middle of this range.\n",
    "   - The lower whisker extends down close to 0, while the upper whisker reaches up to around 700+ seconds, indicating that while most events occur within a mid-range of time, there are some relatively high values.\n",
    "   - Overall, the distribution is right-skewed with a strong concentration near the lower end but still has a substantial midrange.\n",
    "\n",
    "2. **`time_diff`**  \n",
    "   - The box is nearly flat around zero, meaning that most time differences are very small (often near zero).\n",
    "   - There is a very high frequency of near-zero values, with a long tail stretching to larger values (up to ~500 seconds), confirming that while most events occur in rapid succession, a few have significant time gaps.\n",
    "   - This confirms the extreme right-skew, with the bulk of the data clustered at very small time intervals.\n",
    "\n",
    "3. **`distance`**  \n",
    "   - The IQR for distance is approximately 0 to 200, with the median in the lower half of this range.\n",
    "   - The upper whisker extends to roughly 400, and a long tail reaches up to around 1000, indicating that while most movements are relatively small, some events capture larger spatial movements.\n",
    "   - The distribution exhibits multiple modes at lower distances, reflecting common short movements, and a long tail for less frequent, longer movements.\n",
    "\n",
    "4. **`velocity`**  \n",
    "   - Similar to `time_diff`, the box for velocity is pinned near zero, indicating that most events have very low computed velocities.\n",
    "   - However, there is a large set of outliers with velocity values extending up to nearly 9000. This suggests that when even moderate spatial movement is divided by a very small time difference, the resulting velocity can be extremely high.\n",
    "   - The strong right skew in velocity is evident, with most values clustered very close to zero and a few very high values in the tail.\n",
    "\n",
    "**Overall Implications:**\n",
    "\n",
    "- The strong right-skewness across all features suggests that while many events involve minimal movement or occur in quick succession, a subset of events captures substantial changes.\n",
    "- These distributions highlight the need for careful handling in subsequent modeling stages—such as normalization or transformation—to account for the skew and potential outliers.\n",
    "- The insights from these boxplots will inform how we preprocess our data for robust predictive modeling of player trajectories and event detection.\n",
    "\n",
    "With these observations in hand, we have a solid understanding of the data's distribution. We are now ready to proceed to the next section of our EDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fa98f",
   "metadata": {},
   "source": [
    "### 6.3 Spatial Trajectory Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1422e",
   "metadata": {},
   "source": [
    "In this section, we explore the spatial dimensions of the tracking data by visualizing the movement trajectories on the court. Our objectives are to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c51789",
   "metadata": {},
   "source": [
    "\n",
    "- **Visualize Player Movement:**  \n",
    "  Create scatter plots of the X and Y coordinates (`locX` vs. `locY`) to capture the spatial trajectory of players over time.\n",
    "  \n",
    "- **Color-code by Time:**  \n",
    "  Use a color scale based on the in-game time (`cl_seconds`) to help identify how movement changes throughout a period.\n",
    "\n",
    "- **Identify Patterns:**  \n",
    "  Visualize trajectories to see spatial clustering, directional movement, and potential differences between offensive and defensive actions.\n",
    "\n",
    "By visualizing these trajectories, we can gain insights into player behavior, court positioning, and tactical formations that can later inform our predictive modeling efforts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4930a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a sample player (for example, the first unique player in the dataset)\n",
    "sample_player = df_tracking['pid'].unique()[0]\n",
    "\n",
    "# Filter the data for the selected player\n",
    "player_data = df_tracking[df_tracking['pid'] == sample_player]\n",
    "\n",
    "# Create a scatter plot of locX vs. locY, with the color representing in-game time (cl_seconds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(player_data['locX'], player_data['locY'], \n",
    "                      c=player_data['cl_seconds'], cmap='viridis', s=20, alpha=0.7)\n",
    "plt.colorbar(scatter, label='In-Game Time (seconds)')\n",
    "plt.xlabel('locX')\n",
    "plt.ylabel('locY')\n",
    "plt.title(f\"Spatial Trajectory for Player {sample_player}\")\n",
    "\n",
    "# Optionally, invert the y-axis if needed to better reflect the court's orientation\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b28f1",
   "metadata": {},
   "source": [
    "#### 6.3.1 Player 0 Movement Analysis and Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24f375",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "Based on our comprehensive tracking data analysis, we examined the spatial trajectories and movement patterns of Player 0 over a typical period. The data reveals clear, recurring patterns in both offensive and defensive contexts, offering valuable insights into his role on the court.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37401a",
   "metadata": {},
   "source": [
    "**Key Findings:**\n",
    "\n",
    "- **Frequent Hotspots:**  \n",
    "  - Player 0's positions tend to cluster along two distinct arcs. One cluster appears in the lower to mid-range of the court (approximately with `locY` between 100 and 300), and another cluster emerges around `locY` values between 400 and 500.  \n",
    "  - These hotspots suggest that Player 0 consistently occupies key areas of the court, which may be critical for initiating offensive plays or providing defensive support.\n",
    "\n",
    "- **Wide Horizontal Coverage:**  \n",
    "  - The `locX` values range from about -200 to +200, indicating that Player 0 is active across the entire width of the court.  \n",
    "  - This horizontal spread is consistent with a player who is involved in transitioning from one side of the court to the other, contributing to both offensive spacing and defensive balance.\n",
    "\n",
    "- **Temporal Patterns:**  \n",
    "  - The color gradient in the trajectory visualizations (representing in-game time) shows that Player 0 revisits these key zones throughout the game rather than following a linear progression.  \n",
    "  - This recurring pattern indicates a structured movement strategy, likely driven by play design, where the player returns to specific areas at multiple points during the game.\n",
    "\n",
    "- **Movement Dynamics:**  \n",
    "  - There are distinct moments of high velocity (suggesting rapid movements during fast breaks or quick transitions) and periods of near-zero velocity (indicating stationary positioning for play setup or defensive alignment).  \n",
    "  - The combination of these dynamic patterns illustrates that Player 0 is both a mover on the court and someone who can hold position when necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503d7d4",
   "metadata": {},
   "source": [
    "**Tactical Implications:**\n",
    "\n",
    "- **Offensive Role:**  \n",
    "  - The consistent presence in the primary arcs suggests that Player 0 plays a key role in spacing the floor, which is essential for creating driving lanes and facilitating ball movement.\n",
    "  - His positioning may also be leveraged for perimeter shooting, stretching the defense, and opening opportunities for teammates.\n",
    "\n",
    "- **Defensive Role:**  \n",
    "  - The recurrent clustering in specific areas may reflect his responsibilities on defense—particularly in guarding crucial zones around the perimeter.\n",
    "  - Recognizing these patterns can help in planning defensive rotations and adjustments.\n",
    "\n",
    "- **Coaching Insights:**  \n",
    "  - The data confirms that Player 0’s movement is both deliberate and structured. Coaches can use this information to design plays that maximize his strengths (e.g., pick-and-roll opportunities, perimeter spacing) and to adjust tactics if opponents start to exploit predictable patterns.\n",
    "  - Additionally, understanding the moments of high velocity can help in strategizing transitions and fast-break scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862818c",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "The tracking data provides compelling evidence that Player 0 consistently operates within specific zones on the court, with movement patterns that indicate a balance between dynamic transitions and deliberate positioning. These insights suggest that Player 0 is a perimeter-centric player who plays a critical role in both offensive setups and defensive schemes. Incorporating these findings into play design and tactical adjustments could further enhance team performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b06d3b",
   "metadata": {},
   "source": [
    "#### 6.3.2 Spatial Trajectory Scatterplots for Random Players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df32e80",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we aim to visualize the spatial trajectories (i.e., the `(locX, locY)` positions) for 15 randomly selected players. To ensure that our visualization is representative, we will only consider players who have a sufficient number of events (for example, at least 50 events) in the dataset.\n",
    "\n",
    "For each selected player, we will create a scatterplot where:\n",
    "- The X-axis represents the `locX` coordinate.\n",
    "- The Y-axis represents the `locY` coordinate.\n",
    "- Each dot is color-coded by the in-game time (`cl_seconds`), which helps us see the temporal progression of the player's movement.\n",
    "\n",
    "We will arrange the scatterplots in a grid with 3 rows and 5 columns. This layout provides an effective side-by-side comparison of the movement patterns of different players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set a threshold for the minimum number of events per player (e.g., 50 events)\n",
    "min_events = 50\n",
    "\n",
    "# Get a list of player IDs that have at least 'min_events' events\n",
    "players_with_enough_data = df_tracking.groupby('pid').filter(lambda x: len(x) >= min_events)['pid'].unique()\n",
    "\n",
    "# Randomly select 15 players from this list\n",
    "np.random.seed(42)  # For reproducibility\n",
    "selected_players = np.random.choice(players_with_enough_data, size=15, replace=False)\n",
    "\n",
    "# Create a grid of subplots (3 rows x 5 columns)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each selected player and plot their spatial trajectory\n",
    "for ax, player in zip(axes, selected_players):\n",
    "    # Filter data for the current player\n",
    "    player_data = df_tracking[df_tracking['pid'] == player]\n",
    "    \n",
    "    # Create a scatter plot: locX vs. locY, color-coded by cl_seconds\n",
    "    scatter = ax.scatter(player_data['locX'], player_data['locY'], c=player_data['cl_seconds'], \n",
    "                         cmap='viridis', s=20, alpha=0.7)\n",
    "    ax.set_title(f\"Player {player}\")\n",
    "    ax.set_xlabel(\"locX\")\n",
    "    ax.set_ylabel(\"locY\")\n",
    "    # Optionally, invert the y-axis if needed to better reflect court orientation\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Add a colorbar to the figure for cl_seconds\n",
    "# cbar = fig.colorbar(scatter, ax=axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "# cbar.set_label(\"In-Game Time (seconds)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152f858",
   "metadata": {},
   "source": [
    "#### 6.3.3 Conclusion: Spatial Trajectory Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc4e59",
   "metadata": {},
   "source": [
    "The spatial trajectory visualizations have provided valuable insights into player movement patterns over the course of a game. Key observations include:\n",
    "\n",
    "- **Recurring Movement Patterns:**  \n",
    "  The scatterplots reveal that players tend to occupy specific areas on the court repeatedly. For example, many trajectories form curved arcs, suggesting that players often move along the perimeter (possibly near the three-point line) and then transition toward the paint.\n",
    "\n",
    "- **Temporal Dynamics:**  \n",
    "  The color gradient based on `cl_seconds` shows that players revisit these key areas throughout the game rather than progressing linearly. This temporal layering indicates that a player’s positioning is dynamic and adapts to different phases of play.\n",
    "\n",
    "- **Spatial Distribution:**  \n",
    "  The trajectories demonstrate wide horizontal movement across the court, with `locX` values spanning a broad range. Vertical movement (`locY`) also varies significantly, highlighting periods of both concentrated and scattered activity depending on the game context.\n",
    "\n",
    "- **Contextual Implications:**  \n",
    "  - Areas with dense clustering may represent strategic zones (such as offensive hotspots or defensive strongholds).  \n",
    "  - Outlier points in the trajectories could correspond to fast breaks, transitions, or brief defensive adjustments.  \n",
    "  - The variability in the movement patterns underscores the importance of integrating additional contextual data (e.g., shot attempts, rebounds) to fully interpret these spatial trends.\n",
    "\n",
    "Overall, these visualizations confirm that the spatial data is rich in information about player behavior and court positioning. The insights gathered here will be crucial for refining our predictive models and developing tactical recommendations. With a robust understanding of spatial trajectories, we can now proceed to further analyses, such as correlation analysis and event-specific insights, in subsequent sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef84ad2",
   "metadata": {},
   "source": [
    "### 6.4 Correlation Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf9861",
   "metadata": {},
   "source": [
    "In this section, we will examine the correlations between the key features in our dataset. Our objectives are to:\n",
    "\n",
    "- **Quantify Relationships:**  \n",
    "  Compute the pairwise correlation coefficients among both the original and engineered features (e.g., `cl_seconds`, `time_diff`, `locX`, `locY`, `dx`, `dy`, `distance`, and `velocity`).\n",
    "\n",
    "- **Identify Strong Associations:**  \n",
    "  Use a correlation matrix and heatmap to identify which features are strongly correlated, either positively or negatively. This helps us understand potential redundancies and interdependencies in the data.\n",
    "\n",
    "- **Implications for Modeling:**  \n",
    "  - Features that are highly correlated may provide redundant information and could be candidates for dimensionality reduction or careful feature selection.\n",
    "  - Strong correlations can also reveal underlying patterns or relationships that might be critical for the predictive modeling of player trajectories and game events.\n",
    "\n",
    "By visualizing the correlation matrix, we can gain insights into the structure of our data and make informed decisions for subsequent modeling steps.\n",
    "\n",
    "Next, we will proceed to compute and visualize these correlations using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the key features for correlation analysis\n",
    "features_for_corr = ['cl_seconds', 'time_diff', 'locX', 'locY', 'dx', 'dy', 'distance', 'velocity']\n",
    "\n",
    "# Compute the correlation matrix for these features\n",
    "corr_matrix = df_tracking[features_for_corr].corr()\n",
    "\n",
    "# Create a heatmap to visualize the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True,\n",
    "            cbar_kws={\"shrink\": 0.75})\n",
    "plt.title(\"Correlation Matrix for Key Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829d41c",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1a8bc",
   "metadata": {},
   "source": [
    "The correlation matrix provides valuable insights into the relationships among our key features:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667318fb",
   "metadata": {},
   "source": [
    "\n",
    "1. **Spatial Relationships:**\n",
    "   - **Strong Positive Associations:**  \n",
    "     - `locX` and `dx` (0.70) and `locY` and `dy` (0.65) indicate that the changes in positions are consistent with the actual coordinates. This confirms that our method for computing spatial differences is sound.\n",
    "   - **Weak Associations:**  \n",
    "     - The near-zero correlation between `locX` and `locY` suggests that horizontal and vertical positions vary largely independently, which is expected given the nature of court positioning.\n",
    "\n",
    "2. **Temporal and Movement Dynamics:**\n",
    "   - **Time and Velocity:**  \n",
    "     - A modest negative correlation between `cl_seconds` and `velocity` (-0.19) implies that, as the game progresses, players tend to move slightly slower. This could be due to fatigue or tactical adjustments as the period advances.\n",
    "   - **Time Differences:**  \n",
    "     - The weak correlation between `cl_seconds` and `time_diff` (0.02) indicates that the frequency of events is relatively independent of the period’s progression.\n",
    "\n",
    "3. **Distance and Velocity:**\n",
    "   - **Moderate Association:**  \n",
    "     - The positive correlation between `distance` and `velocity` (0.32) confirms the intuitive expectation that higher velocities correspond to greater distances covered. However, the correlation is not very high, suggesting that other factors (e.g., diagonal movements or variations in event timing) also influence the overall movement.\n",
    "\n",
    "4. **Overall Implications:**\n",
    "   - The strong spatial correlations validate our engineered features, while the time-based variables and their relationships with velocity offer insights into game dynamics such as pacing and potential fatigue.\n",
    "   - Some features exhibit weak or unexpected correlations (e.g., the negligible correlation between `distance` and individual spatial differences `dx`/`dy`), indicating that movement is likely a combination of both horizontal and vertical changes and may be influenced by diagonal trajectories.\n",
    "   - These insights provide a basis for further analysis, such as exploring event-level contexts and considering additional combined metrics, to fully capture the complexities of player movement.\n",
    "\n",
    "In summary, the correlation matrix reveals that while our spatial features are strongly interrelated, the temporal and derived movement metrics exhibit more nuanced relationships. These findings will help guide our next steps in feature selection and model development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903dd24",
   "metadata": {},
   "source": [
    "## 7. Data Quality & Anomaly Detection <a id=\"data-quality\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972a566",
   "metadata": {},
   "source": [
    "\n",
    "In this chapter, we shift our focus to the overall quality of the dataset and the identification of any anomalies. Our objectives in this section are to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23524dd",
   "metadata": {},
   "source": [
    "\n",
    "1. **Assess Data Quality:**\n",
    "   - Evaluate the completeness, consistency, and accuracy of the data.\n",
    "   - Check for any systematic issues (e.g., missing values, data entry errors, or unexpected patterns) that might affect the integrity of our engineered features.\n",
    "\n",
    "2. **Detect Anomalies:**\n",
    "   - Identify outliers and unusual patterns in both the original and engineered features.\n",
    "   - Use statistical methods (e.g., Z-scores, Interquartile Range) and visual tools (e.g., boxplots) to flag observations that deviate significantly from the norm.\n",
    "   - Investigate whether these anomalies are genuine (e.g., moments of exceptional movement during fast breaks) or are artifacts of data collection/processing.\n",
    "\n",
    "3. **Interpretation and Implications:**\n",
    "   - Discuss the potential reasons for any detected anomalies, such as measurement errors, specific game events (e.g., timeouts, transitions), or data recording issues.\n",
    "   - Evaluate the impact of these anomalies on the overall dataset and on subsequent modeling efforts.\n",
    "   - Consider strategies for handling anomalies (e.g., imputation, removal, or transformation) to ensure that our models are robust and not overly influenced by extreme values.\n",
    "\n",
    "4. **Next Steps:**\n",
    "   - Based on our findings, determine if additional preprocessing is required (e.g., normalization, outlier treatment).\n",
    "   - Plan further analyses or modeling adjustments informed by the data quality and anomaly detection results.\n",
    "\n",
    "By thoroughly assessing the data quality and detecting anomalies, we ensure that our feature set is reliable and that our subsequent modeling steps are based on high-quality, representative data.\n",
    "\n",
    "Next, we will implement the analysis methods to quantify data quality and identify potential anomalies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8c214",
   "metadata": {},
   "source": [
    "### 7.1 Outlier Detection using the IQR Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8412d",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we will detect outliers in key numerical features using the Interquartile Range (IQR) method. The IQR method identifies outliers as observations that fall below:\n",
    "\n",
    "$$ Q1 - 1.5 \\times IQR $$\n",
    "\n",
    "or above:\n",
    "\n",
    "$$ Q3 + 1.5 \\times IQR $$\n",
    "\n",
    "where \\(Q1\\) and \\(Q3\\) are the 25th and 75th percentiles, respectively, and \\(IQR = Q3 - Q1\\).\n",
    "\n",
    "We will apply this method to the following key features:\n",
    "- `cl_seconds`\n",
    "- `time_diff`\n",
    "- `distance`\n",
    "- `velocity`\n",
    "\n",
    "Our goals are to:\n",
    "- Quantify the number of outliers for each feature.\n",
    "- Display a sample of the outlier data for further inspection.\n",
    "\n",
    "This analysis will help us understand if extreme values exist in our dataset and determine the appropriate strategies (e.g., normalization, transformation, or removal) for handling them during modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to detect outliers using the IQR method for a given feature\n",
    "def detect_outliers_iqr(data, feature):\n",
    "    Q1 = data[feature].quantile(0.25)\n",
    "    Q3 = data[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[feature] < lower_bound) | (data[feature] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# List of key features for outlier detection\n",
    "numeric_features = ['cl_seconds', 'time_diff', 'distance', 'velocity']\n",
    "\n",
    "# Dictionary to store outlier information for each feature\n",
    "outliers_dict = {}\n",
    "\n",
    "for feature in numeric_features:\n",
    "    outliers, lower_bound, upper_bound = detect_outliers_iqr(df_tracking, feature)\n",
    "    outliers_dict[feature] = outliers\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eae953",
   "metadata": {},
   "source": [
    "#### Analysis and Conclusions: Outlier Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b03b89",
   "metadata": {},
   "source": [
    "\n",
    "From the IQR-based outlier detection, we obtained the following results:\n",
    "\n",
    "- **cl_seconds:**  \n",
    "  - Lower bound: -375.00, Upper bound: 1049.00  \n",
    "  - **Observation:** No outliers were detected for `cl_seconds`, which suggests that the in-game time (converted to seconds) is well-behaved and within the expected range (0 to 720 seconds for a 12-minute period).\n",
    "\n",
    "- **time_diff:**  \n",
    "  - Lower bound: -1.50, Upper bound: 2.50  \n",
    "  - **Observation:** A large number of outliers (33,454 observations) were detected.  \n",
    "  - **Interpretation:** The majority of `time_diff` values are very small (close to zero), which is expected since many events occur in rapid succession. However, there are some events with much larger gaps, likely due to period transitions or pauses. These extreme values stretch the distribution and are flagged as outliers.\n",
    "\n",
    "- **distance:**  \n",
    "  - Lower bound: -225.25, Upper bound: 544.18  \n",
    "  - **Observation:** 4,730 outlier observations were detected.  \n",
    "  - **Interpretation:** While many movements are small, some events show unusually high Euclidean distances, indicating substantial movement between events. These could be genuine (e.g., fast breaks) or might be influenced by measurement noise.\n",
    "\n",
    "- **velocity:**  \n",
    "  - Lower bound: -189.60, Upper bound: 316.00  \n",
    "  - **Observation:** 22,976 outlier observations were found.  \n",
    "  - **Interpretation:** The computed velocity shows a high degree of skewness. A substantial number of events yield very high velocities, which are likely the result of dividing moderate distances by very small time differences (e.g., 0.1 seconds). This can produce extreme values even if the actual movement is moderate.\n",
    "\n",
    "**Overall Analysis and Implications:**\n",
    "\n",
    "- The **lack of outliers in `cl_seconds`** confirms that the conversion of the in-game clock is consistent.\n",
    "- The extremely high count of outliers in **`time_diff` and `velocity`** is largely due to the fact that most events occur with very small time differences, resulting in a clustering near zero and a long tail of high values.\n",
    "- The presence of outliers in **`distance`** indicates that while many movements are small, some events capture unusually large displacements.\n",
    "- **High velocity values** should be interpreted with caution, as they are sensitive to very small time differences. It might be useful to further investigate these cases, determine whether they represent genuine bursts of speed (e.g., during fast breaks) or artifacts of data collection, and consider normalization or capping of extreme values if necessary.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. **Investigate Extreme Values:**  \n",
    "   - Look into events with very high `velocity` to determine if they correspond to specific game events (like fast breaks) or if they are anomalies due to measurement issues.\n",
    "   \n",
    "2. **Consider Data Transformation:**  \n",
    "   - Depending on the modeling requirements, consider applying transformations (e.g., logarithmic scaling) or capping extreme outlier values to mitigate their impact on downstream analysis.\n",
    "   \n",
    "3. **Integrate Context:**  \n",
    "   - Explore linking these extreme movement events with other game context (e.g., play types, shot attempts, turnovers) to better understand their significance.\n",
    "\n",
    "With these insights, we have a better understanding of the data quality and the nature of anomalies present in our dataset. The next phase is to proceed with further visualizations and contextual analyses, which will help us refine our feature set before moving into predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f53256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optionally, display a sample of outliers for one feature (e.g., velocity)\n",
    "print(\"\\nSample outliers for 'velocity':\")\n",
    "display(outliers_dict['velocity'].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c4ae5",
   "metadata": {},
   "source": [
    "#### Analyzing Player Participation and Filtering Low-Activity Players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c7dab",
   "metadata": {},
   "source": [
    "\n",
    "To ensure that our analysis and subsequent modeling are based on robust data, we need to identify and filter out players who have very limited participation in the game. Players with very few events may not provide enough information for reliable analysis, and including them could introduce noise into our models.\n",
    "\n",
    "**Our Approach:**\n",
    "\n",
    "1. **Count Events per Player:**  \n",
    "   - We will compute the total number of events associated with each player (using the `pid` field).\n",
    "   - This count will serve as a measure of each player's activity level during the game.\n",
    "\n",
    "2. **Visualize the Distribution of Event Counts:**  \n",
    "   - By plotting a histogram or boxplot of the number of events per player, we can observe the spread of participation.\n",
    "   - This visualization will help us determine a reasonable threshold for what constitutes “sufficient” participation.\n",
    "\n",
    "3. **Filter Out Low-Participation Players:**  \n",
    "   - Based on the distribution, we will define a threshold (for example, players with fewer than 50 events) and remove these players from our dataset.\n",
    "   - This step ensures that our analysis focuses on players with adequate data, improving the reliability and robustness of our findings.\n",
    "\n",
    "By taking these steps, we can ensure that our dataset includes only those players whose movement patterns are well-represented in the data, leading to more accurate and meaningful analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the count of events per player\n",
    "event_counts = df_tracking['pid'].value_counts()\n",
    "\n",
    "# Display summary statistics of event counts per player\n",
    "print(\"Summary Statistics for Event Counts per Player:\")\n",
    "print(event_counts.describe())\n",
    "\n",
    "# Plot a histogram of the event counts per player\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(event_counts, bins=30, kde=True, color='skyblue')\n",
    "plt.title(\"Distribution of Events per Player (pid)\")\n",
    "plt.xlabel(\"Number of Events\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca39366",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the count of events per player\n",
    "event_counts = df_tracking['pid'].value_counts()\n",
    "\n",
    "# Plot a boxplot for the distribution of event counts per player\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=event_counts, color='lightblue')\n",
    "plt.title(\"Boxplot of Event Counts per Player\")\n",
    "plt.xlabel(\"Number of Events\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdcc379",
   "metadata": {},
   "source": [
    "#### Brief Report: Boxplot Analysis of Event Counts per Player (Including `pid=0`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23180bff",
   "metadata": {},
   "source": [
    "##### 1. Distribution & Spread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67609e1",
   "metadata": {},
   "source": [
    "- **Central Tendency:**\n",
    "  - The majority of players have event counts clustered below **2,000**. The interquartile range (IQR) is relatively tight.\n",
    "  - The **median** event count appears to fall just below **1,000**, indicating that half of the players contribute relatively few events.\n",
    "  \n",
    "- **Spread:**\n",
    "  - Most players are grouped within a narrow range of event counts.\n",
    "  - However, a long right tail is evident, with a few players showing extremely high event counts—up to **25,000** events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03e1db",
   "metadata": {},
   "source": [
    "##### 2. Outlier Examination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682114d1",
   "metadata": {},
   "source": [
    "- **Extreme Outliers:**\n",
    "  - The player with over **25,000 events** (likely represented by `pid=0`) is a clear outlier.\n",
    "  - This extreme count could indicate either a star player with significantly higher involvement or, alternatively, a data artifact (such as duplicate tracking or inclusion of non-player entities).\n",
    "  \n",
    "- **Star Players or Errors?**\n",
    "  - While star players can naturally accumulate more events due to high minutes and involvement, such an extreme value warrants verification.\n",
    "  - Cross-referencing with game logs and roster data is necessary to confirm whether this outlier is valid.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8bf938",
   "metadata": {},
   "source": [
    "##### 3. Data Quality & Implications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c1584",
   "metadata": {},
   "source": [
    "- **Legitimacy of Outliers:**\n",
    "  - Extreme outliers like `pid=0` may distort summary statistics (e.g., mean) and can bias subsequent analyses if not handled appropriately.\n",
    "  \n",
    "- **Impact on Analysis:**\n",
    "  - Including extreme outliers may skew our understanding of typical player behavior.\n",
    "  - It may be beneficial to treat or filter such outliers (e.g., through capping or removal) depending on our analysis goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d39e1",
   "metadata": {},
   "source": [
    "##### Recommendations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930d85a",
   "metadata": {},
   "source": [
    "- **Verification:**  \n",
    "  - Confirm that the extremely high event count for `pid=0` aligns with actual playing time and role, or if it is an artifact.\n",
    "  \n",
    "- **Filtering for Typical Analysis:**  \n",
    "  - Consider excluding players with extremely low or extremely high event counts (after verification) to focus on the majority of players whose activity levels are more representative.\n",
    "\n",
    "**Summary:**  \n",
    "The boxplot analysis including `pid=0` reveals a heavily right-skewed distribution, with the median below 1,000 events and a single extreme outlier exceeding 25,000 events. This suggests that while most players have modest activity, a few cases need further investigation to ensure data quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove player with id=0 from the DataFrame\n",
    "df_non_zero = df_tracking[df_tracking['pid'] != 0]\n",
    "\n",
    "# Calculate the count of events per player (excluding player 0)\n",
    "event_counts = df_non_zero['pid'].value_counts()\n",
    "\n",
    "# Plot a boxplot for the distribution of event counts per player\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=event_counts, color='lightblue')\n",
    "plt.title(\"Boxplot of Event Counts per Player (excluding player 0)\")\n",
    "plt.xlabel(\"Number of Events\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac9d11",
   "metadata": {},
   "source": [
    "#### Refined Analysis: Boxplot of Event Counts (Excluding `pid=0`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca792d11",
   "metadata": {},
   "source": [
    "##### Key Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29656a",
   "metadata": {},
   "source": [
    "1. **Central Tendency & Spread:**\n",
    "   - **Median:**  \n",
    "     The median event count is approximately **500 events**, indicating that half of the players (excluding `pid=0`) have fewer than around 500 recorded events.\n",
    "   - **Interquartile Range (IQR):**  \n",
    "     The IQR spans roughly from **250 to 700 events**, which captures the middle 50% of players, suggesting a relatively modest participation level for most.\n",
    "\n",
    "2. **Right-Skew & Outliers:**\n",
    "   - The overall distribution remains right-skewed, with a small number of players showing higher event counts.\n",
    "   - There are two notable outliers with counts in the range of **1,500 to 1,750 events**, which are plausible for players with significant court time.\n",
    "\n",
    "3. **Scale Adjustment:**\n",
    "   - By excluding `pid=0`, the distribution now focuses on typical player participation, with the x-axis extending only to about 1,750 events. This improves visualization and better represents the majority of players."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d4f50",
   "metadata": {},
   "source": [
    "##### Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6eea1",
   "metadata": {},
   "source": [
    "- **Impact of Excluding `pid=0`:**\n",
    "  - Removing the extreme outlier (`pid=0`) reduces the skew of the distribution, enabling a clearer view of the event counts for the bulk of the players.\n",
    "  - The refined distribution reveals that most players contribute between **250 and 700 events**, which is more representative of typical participation levels in a game.\n",
    "\n",
    "- **Remaining Outliers:**\n",
    "  - The few players with event counts near 1,750 likely represent key contributors (e.g., star players) with high playing time.\n",
    "  - These outliers, while still present, are within a more plausible range compared to the extreme value from `pid=0`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86cc494",
   "metadata": {},
   "source": [
    "##### Recommendations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f20ecc",
   "metadata": {},
   "source": [
    "\n",
    "1. **Outlier Validation:**  \n",
    "   - Investigate the two players with high event counts (~1,750) to confirm they are indeed high-usage players.\n",
    "   \n",
    "2. **Focus on Active Participants:**  \n",
    "   - For further analysis and modeling, consider filtering out players with very low event counts (e.g., below 500) to concentrate on those who are actively contributing.\n",
    "\n",
    "3. **Modeling Considerations:**  \n",
    "   - Use robust statistical measures (e.g., median) when summarizing data, and consider normalizing event counts to reduce the influence of remaining outliers.\n",
    "\n",
    "**Summary:**  \n",
    "Excluding `pid=0` significantly refines the distribution of event counts. Most players now fall within a typical range of 250–700 events, with a few key players showing higher counts. This refined view allows for a more balanced analysis and supports subsequent modeling efforts by focusing on the most relevant data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d634513",
   "metadata": {},
   "source": [
    "### 7.2 Outlier Detection for Player Event Counts (Excluding `pid=0`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bb500b",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we focus on analyzing player participation by examining the distribution of event counts per player, while explicitly excluding the extreme case of `pid=0`. Our objectives are to:\n",
    "\n",
    "- **Quantify Player Activity:**  \n",
    "  Compute the total number of events recorded for each player (using the `pid` field) to understand overall participation levels.\n",
    "\n",
    "- **Apply the IQR Method:**  \n",
    "  Calculate the first (Q1) and third (Q3) quartiles and the Interquartile Range (IQR) for the event counts. Using these, determine the lower boundary as:\n",
    "  \n",
    "  $$ \\text{Lower Bound} = Q1 - 1.5 \\times \\text{IQR} $$\n",
    "  \n",
    "  and the upper boundary as:\n",
    "  \n",
    "  $$ \\text{Upper Bound} = Q3 + 1.5 \\times \\text{IQR} $$\n",
    "  \n",
    "- **Determine Filtering Thresholds:**  \n",
    "  By visualizing and quantifying the distribution, we can decide on a minimum event count threshold. This threshold will help us filter out players with very low participation (e.g., fewer than 500 events) so that our subsequent analysis and modeling are based on robust player data.\n",
    "\n",
    "Let's now implement the IQR-based outlier detection on the event counts, after excluding `pid=0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904fb106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Exclude pid=0 from the analysis\n",
    "filtered_data = df_tracking[df_tracking['pid'] != 0]\n",
    "\n",
    "# Calculate event counts per player\n",
    "event_counts = filtered_data['pid'].value_counts()\n",
    "\n",
    "# Display summary statistics for event counts\n",
    "print(\"Summary Statistics for Event Counts (excluding pid=0):\")\n",
    "print(event_counts.describe())\n",
    "\n",
    "# Calculate Q1, Q3, and IQR for event counts\n",
    "Q1 = event_counts.quantile(0.25)\n",
    "Q3 = event_counts.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"\\nIQR for event counts: {IQR:.2f}\")\n",
    "print(f\"Lower Bound: {lower_bound:.2f}\")\n",
    "print(f\"Upper Bound: {upper_bound:.2f}\")\n",
    "\n",
    "# Identify outlier players based on event counts\n",
    "outlier_players = event_counts[(event_counts < lower_bound) | (event_counts > upper_bound)]\n",
    "print(f\"\\nNumber of outlier players (excluding pid=0): {len(outlier_players)}\")\n",
    "print(\"Outlier event counts:\")\n",
    "print(outlier_players)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba91a2",
   "metadata": {},
   "source": [
    "#### Event Counts per Player & Filtering Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0fb2ca",
   "metadata": {},
   "source": [
    "\n",
    "**Summary of Findings:**\n",
    "- **Event Count Distribution (Excluding `pid=0`):**  \n",
    "  - **Count:** 583 players  \n",
    "  - **Mean:** ~486 events  \n",
    "  - **Median:** 373 events  \n",
    "  - **25th Percentile:** 101.5 events  \n",
    "  - **75th Percentile:** 768.5 events  \n",
    "  - **Max:** 1882 events  \n",
    "- **IQR Analysis:**  \n",
    "  - The Interquartile Range (IQR) is 667.00, which results in a calculated upper bound of 1769.00 (using \\( Q3 + 1.5 \\times IQR \\)).  \n",
    "  - There are 2 players with event counts exceeding this upper bound (1882 and 1804), which likely correspond to star players or possibly data anomalies.\n",
    "\n",
    "**Implications:**\n",
    "- The majority of players have modest event counts, with a median of 373, while a small subset of players are extremely active.\n",
    "- The lower boundary calculated via IQR is negative (-899), which is not useful for filtering; instead, we need to set a practical threshold to exclude players with very low participation.\n",
    "- Given that the 25th percentile is around 101 events and the median is 373 events, it may be reasonable to filter out players with extremely low counts (e.g., below 250 events) to focus our analysis on players with sufficient on-court activity.\n",
    "\n",
    "**Recommendations for Next Steps:**\n",
    "1. **Set a Lower Threshold:**  \n",
    "   - We recommend filtering out players with fewer than **250 events**. This threshold helps ensure that our analysis and modeling are based on players with enough data to capture meaningful movement patterns.\n",
    "2. **Remove Low-Participation Players:**  \n",
    "   - Apply this threshold to further refine the dataset.\n",
    "3. **Re-Evaluate Distribution:**  \n",
    "   - After filtering, re-examine the distribution of event counts to ensure the dataset reflects the active participants.\n",
    "4. **Proceed with Analysis:**  \n",
    "   - With the filtered dataset, we can then integrate these robust player-level features into further exploratory analysis and modeling.\n",
    "\n",
    "This refined approach will help us focus on the most representative players, thereby improving the quality and interpretability of our subsequent analyses and models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7257d8",
   "metadata": {},
   "source": [
    "#### Filtering Low-Participation Players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1510b1",
   "metadata": {},
   "source": [
    "\n",
    "Based on our outlier analysis of event counts per player, we determined that:\n",
    "- We will exclude `pid=0`, which represents an extreme outlier.\n",
    "- We will also filter out players with fewer than 250 events to focus our analysis on those with sufficient on-court activity.\n",
    "\n",
    "This filtering step will result in a cleaner dataset that is more representative of players with meaningful participation. Next, we will apply these filters to our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of events per player (excluding pid=0, if not already filtered)\n",
    "event_counts = df_tracking[df_tracking['pid'] != 0]['pid'].value_counts()\n",
    "\n",
    "# Identify eligible players: those with at least 250 events\n",
    "eligible_pids = event_counts[event_counts >= 250].index\n",
    "\n",
    "# Filter the dataset to include only eligible players\n",
    "df_filtered = df_tracking[df_tracking['pid'].isin(eligible_pids)]\n",
    "\n",
    "# Display the number of players and total events in the filtered dataset\n",
    "print(\"Number of players after filtering:\", df_filtered['pid'].nunique())\n",
    "print(\"Total number of events in filtered dataset:\", len(df_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031be7ed",
   "metadata": {},
   "source": [
    "### 7.3 Final Exploratory Data Analysis on Cleaned Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5e7a7",
   "metadata": {},
   "source": [
    "With our dataset now filtered to exclude `pid=0` and players with fewer than 250 events, we have a more robust subset consisting of 336 players and 260,246 events. In this section, we will re-examine key aspects of the data to confirm that our cleaning and preprocessing steps have improved the quality of our dataset. We will focus on:\n",
    "\n",
    "1. **Distribution of Event Counts per Player:**  \n",
    "   - Display a histogram and boxplot of event counts per player to understand the spread of participation.\n",
    "\n",
    "2. **Spatial Trajectory Visualizations:**  \n",
    "   - Visualize the on-court movement for a few (5) randomly selected players from the cleaned dataset using scatterplots.  \n",
    "   - This will help confirm that our spatial features are representative and that players' movement patterns are preserved in the filtered data.\n",
    "\n",
    "3. **Additional Graphs (Optional):**  \n",
    "   - We may include further visualizations (e.g., comparing distributions of key engineered features) to verify the overall data quality.\n",
    "\n",
    "These visualizations will serve as the final confirmation of our preprocessing and cleaning efforts, ensuring that our dataset is ready for the modeling phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315dae5",
   "metadata": {},
   "source": [
    "#### Distribution of Event Counts per Player – Histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7ce26",
   "metadata": {},
   "source": [
    "\n",
    "Below, we plot a histogram of the event counts per player (from the filtered dataset) to visualize the overall participation levels. This helps us see how many events the majority of players contribute and confirms that our filtering criteria are appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Re-calculate event counts per player from the filtered dataset\n",
    "filtered_event_counts = df_filtered['pid'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(filtered_event_counts, bins=30, kde=True, color='steelblue')\n",
    "plt.title(\"Distribution of Event Counts per Player (Filtered)\")\n",
    "plt.xlabel(\"Number of Events\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ae020",
   "metadata": {},
   "source": [
    "#### Distribution of Event Counts per Player – Boxplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708acfd0",
   "metadata": {},
   "source": [
    "\n",
    "The following boxplot provides a visual summary of the event counts per player after filtering. This will help us identify the central tendency, spread, and any remaining outliers among active players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=filtered_event_counts, color='lightgreen')\n",
    "plt.title(\"Boxplot of Event Counts per Player (Filtered)\")\n",
    "plt.xlabel(\"Number of Events\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45926a3",
   "metadata": {},
   "source": [
    "#### Spatial Trajectory Scatterplots for Random Players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c8015",
   "metadata": {},
   "source": [
    "To further understand player movement patterns in our cleaned dataset, we will visualize the spatial trajectories for 15 randomly selected players (arranged in 3 rows and 5 columns). Each scatterplot shows the player's (locX, locY) positions color-coded by the in-game time (`cl_seconds`). \n",
    "\n",
    "To ensure that the spatial comparisons are meaningful, we will set fixed x and y boundaries for all subplots. For our dataset, we set the x-axis limits to [-250, 250] (representing the full horizontal spread on the court) and the y-axis limits to [900, -80] (inverted to reflect a typical court orientation).\n",
    "\n",
    "This consistent scaling allows us to directly compare the positional tendencies and hotspots across different players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b5657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a threshold for minimum events has already been applied in df_filtered.\n",
    "# Randomly select 15 players from the filtered dataset\n",
    "np.random.seed(42)  # For reproducibility\n",
    "selected_players = np.random.choice(df_filtered['pid'].unique(), size=15, replace=False)\n",
    "\n",
    "# Create subplots for 15 players (3 rows x 5 columns)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "# Define consistent x and y limits for all subplots\n",
    "x_limits = (-250, 250)\n",
    "y_limits = (900, -80)  # Inverted y-axis to reflect typical court orientation\n",
    "\n",
    "# Loop through each selected player and plot their spatial trajectory\n",
    "for ax, player in zip(axes, selected_players):\n",
    "    player_data = df_filtered[df_filtered['pid'] == player]\n",
    "    \n",
    "    # Create scatter plot: locX vs. locY, color-coded by cl_seconds\n",
    "    scatter = ax.scatter(player_data['locX'], player_data['locY'], \n",
    "                         c=player_data['cl_seconds'], cmap='viridis', s=20, alpha=0.7)\n",
    "    ax.set_title(f\"Player {player}\")\n",
    "    ax.set_xlabel(\"locX\")\n",
    "    ax.set_ylabel(\"locY\")\n",
    "    ax.set_xlim(x_limits)\n",
    "    ax.set_ylim(y_limits)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9a4d1",
   "metadata": {},
   "source": [
    "### 7.4 Overall Data Summary – Data Quality Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ef4a2",
   "metadata": {},
   "source": [
    "After extensive preprocessing, filtering, and exploratory analyses, we have arrived at a refined dataset that meets our quality standards. Key points include:\n",
    "\n",
    "- **Robust Player Participation:**  \n",
    "  After excluding `pid=0` and players with fewer than 250 events, our dataset now contains 336 players with a total of 260,246 events. This filtering has focused our analysis on active participants, reducing noise from low-activity entries.\n",
    "\n",
    "- **Engineered Features:**  \n",
    "  We have successfully computed and validated several key engineered features:\n",
    "  - **Time Variables:** `cl_seconds` and `time_diff` capture the temporal dynamics.\n",
    "  - **Spatial Variables:** `locX`, `locY`, along with their differences (`dx`, `dy`), quantify on-court positioning.\n",
    "  - **Movement Metrics:** The Euclidean distance and velocity provide insights into the magnitude and speed of player movements.\n",
    "  \n",
    "- **Distribution & Outlier Analysis:**  \n",
    "  Our analysis (histograms, boxplots, and correlation matrices) indicates that while some features are strongly right-skewed with outliers (especially `time_diff` and `velocity`), these characteristics align with the fast-paced and variable nature of NBA play. The majority of players exhibit consistent participation and movement patterns, with extreme values flagged for further investigation.\n",
    "\n",
    "- **Spatial Trajectory Insights:**  \n",
    "  Visualizations of spatial trajectories reveal distinct movement patterns and hotspots, consistent with typical player roles (e.g., perimeter activity for guards, clustering in the paint for big men).\n",
    "\n",
    "Overall, the refined dataset is now robust, representative, and ready for advanced modeling and further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca926895",
   "metadata": {},
   "source": [
    "### 7.5 Saving the Refined Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b967a0",
   "metadata": {},
   "source": [
    "\n",
    "With our dataset now fully cleaned, filtered, and enriched with engineered features, the next step is to save this refined data for future modeling and analysis. Saving the dataset in a structured format (such as CSV) will ensure reproducibility and ease of use in subsequent phases of the project.\n",
    "\n",
    "We will export the refined dataset (`df_filtered`) to a CSV file so that it can be easily loaded for further modeling in Chapter 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43810809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the refined dataset to a CSV file\n",
    "output_path = \"../data/processed/refined_nba_tracking_data.csv\"\n",
    "df_filtered.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Refined dataset saved successfully at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055c8fc",
   "metadata": {},
   "source": [
    "## 8. Next Steps <a id=\"next-steps\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf2b2f",
   "metadata": {},
   "source": [
    "### Summary of Preprocessing and EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fadf1",
   "metadata": {},
   "source": [
    "- **Data Cleaning & Filtering:**  \n",
    "  - We filtered out the extreme outlier (`pid=0`) and players with fewer than 250 events, resulting in a refined dataset of 336 active players and 260,246 events.\n",
    "  - This step ensured that our analysis focuses on players with robust participation, reducing noise from low-activity or potentially erroneous entries.\n",
    "\n",
    "- **Feature Engineering:**  \n",
    "  - We successfully derived key features that capture both temporal and spatial dynamics:\n",
    "    - **Temporal Features:** `cl_seconds` and `time_diff` quantify in-game time and intervals between events.\n",
    "    - **Spatial Features:** `locX`, `locY`, along with their differences (`dx` and `dy`), provide the basis for computing the Euclidean distance (`distance`) and velocity.\n",
    "  - These engineered features provide a solid foundation for understanding player movement patterns and game dynamics.\n",
    "\n",
    "- **Exploratory Data Analysis (EDA):**  \n",
    "  - We examined the distributions (via histograms, KDE, and boxplots) of both raw and engineered features, revealing important characteristics such as right-skewness and the presence of outliers.\n",
    "  - Spatial trajectory visualizations confirmed that players exhibit distinct movement patterns and hotspots on the court.\n",
    "  - Correlation analysis provided insights into the interdependencies among features, further informing our feature selection and preprocessing strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed64f0",
   "metadata": {},
   "source": [
    "### Next Steps: Roadmap for Predictive Modeling and Further Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc3006",
   "metadata": {},
   "source": [
    "1. **Feature Selection & Transformation:**  \n",
    "   - Reassess and potentially normalize or transform highly skewed features (e.g., `time_diff` and `velocity`) to mitigate the influence of extreme values.\n",
    "   - Explore additional derived features (e.g., diagonal movement metrics or acceleration) that may further improve model performance.\n",
    "\n",
    "2. **Predictive Modeling:**  \n",
    "   - Develop baseline predictive models (e.g., using regression, decision trees, or logistic regression) as benchmarks.\n",
    "   - Explore advanced modeling approaches, such as:\n",
    "     - **Sequence Models (LSTMs, Transformers):** For predicting future player trajectories based on historical movement data.\n",
    "     - **Graph Neural Networks (GNNs):** To capture the multi-agent interactions and team dynamics inherent in the sport.\n",
    "\n",
    "3. **Model Evaluation & Validation:**  \n",
    "   - Use appropriate evaluation metrics (e.g., mean squared error, AUC, or log-loss) and cross-validation strategies to assess model performance.\n",
    "   - Conduct error analysis to identify any systematic biases or areas for improvement.\n",
    "\n",
    "4. **Integration of Additional Data:**  \n",
    "   - Incorporate contextual game event data (e.g., play-by-play logs, shot charts, rebounds) to enrich the model’s inputs and better capture the nuances of player behavior.\n",
    "   - Examine how different in-game situations affect player movement and outcomes.\n",
    "\n",
    "5. **Actionable Insights & Tactical Recommendations:**  \n",
    "   - Translate the modeling outcomes into actionable insights for coaches and team analysts.\n",
    "   - Develop dashboards or visual reports to communicate the findings in an intuitive way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ef8c5",
   "metadata": {},
   "source": [
    "### Final Thoughts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092f938",
   "metadata": {},
   "source": [
    "Our comprehensive preprocessing and EDA have prepared us with a high-quality, feature-rich dataset that accurately represents NBA player movements. The next phase will focus on building predictive models that leverage these insights to forecast player trajectories and extract tactical insights, ultimately contributing to more informed decision-making on and off the court."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "nav_menu": {},
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
